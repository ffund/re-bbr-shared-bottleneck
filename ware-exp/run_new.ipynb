{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c863b1b-7267-4445-b954-bdfba7563084",
   "metadata": {},
   "source": [
    "## Reproduce results from “Modeling BBR’s Interactions with Loss-Based Congestion Control”\n",
    "\n",
    "This notebook will reproduce selected findings from\n",
    "\n",
    "> Ranysha Ware, Matthew K. Mukerjee, Srinivasan Seshan, and Justine Sherry. 2019. Modeling BBR’s Interactions with Loss-Based Congestion Control. In Proceedings of the Internet Measurement Conference (IMC ’19). Association for Computing Machinery, New York, NY, USA, 137–143. https://doi.org/10.1145/3355369.3355604\n",
    "\n",
    "specifically,\n",
    "\n",
    "-   Figure 1b and 1c (initial measurements of BBR’s empirical behaviors)\n",
    "-   Figure 2: BBR vs Cubic in a 40ms × 10Mbps network (convergence time and goodput for 1 BBR and 1 Cubic flow over varying queue sizes)\n",
    "-   Figure 3: BBR and Cubic or Reno’s queue when competing for 4 minutes over a network with a 64 BDP (1024 packet) queue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4f0e35-be9f-4be1-b573-975510b4aaa6",
   "metadata": {},
   "source": [
    "The following group of cells installs prerequisites for data analysis and visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fcce08-f485-4d6f-a6cf-000278e06ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dfc036-e4a5-4461-995d-a61f3f2435cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37befed-2b1a-4608-8854-c74cefbd44f6",
   "metadata": {},
   "source": [
    "### Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d621b02-e934-4c92-97bd-2f0831d9675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "fablib = fablib_manager() \n",
    "conf = fablib.show_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ca7467-1ad8-4499-b346-a7315ad7542c",
   "metadata": {},
   "source": [
    "### Define configuration for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65703e50-63fe-45cf-a77e-67097a999712",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_name=\"ware-\" + fablib.get_bastion_username()\n",
    "\n",
    "node_conf = [\n",
    " {'name': \"sender\",    'cores': 2, 'ram': 4, 'disk': 10, 'image': 'default_ubuntu_22', 'packages': ['iperf3']}, \n",
    " {'name': \"receiver\",  'cores': 2, 'ram': 4, 'disk': 10, 'image': 'default_ubuntu_22', 'packages': ['iperf3']}, \n",
    " {'name': \"router\",    'cores': 2, 'ram': 4, 'disk': 10, 'image': 'default_ubuntu_22', 'packages': []}\n",
    "]\n",
    "net_conf = [\n",
    " {\"name\": \"net0\", \"subnet\": \"10.0.0.0/24\", \"nodes\": [{\"name\": \"sender\",   \"addr\": \"10.0.0.100\"}, {\"name\": \"router\", \"addr\": \"10.0.0.1\"}]},\n",
    " {\"name\": \"net1\", \"subnet\": \"10.0.1.0/24\", \"nodes\": [{\"name\": \"receiver\", \"addr\": \"10.0.1.100\"}, {\"name\": \"router\", \"addr\": \"10.0.1.1\"}]},\n",
    "]\n",
    "route_conf = [\n",
    " {\"addr\": \"10.0.1.0/24\", \"gw\": \"10.0.0.1\", \"nodes\": [\"sender\"]}, \n",
    " {\"addr\": \"10.0.0.0/24\", \"gw\": \"10.0.1.1\", \"nodes\": [\"receiver\"]}\n",
    "]\n",
    "exp_conf = {'cores': sum([ n['cores'] for n in node_conf]), 'nic': sum([len(n['nodes']) for n in net_conf]) }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becddaea-c410-4e09-9cfa-9504032d8738",
   "metadata": {},
   "source": [
    "### Reserve resources\n",
    "\n",
    "Now, we are ready to reserve resources!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a878eaf6-5b30-4d76-b6a1-54d88451a7b0",
   "metadata": {},
   "source": [
    "First, make sure you don’t already have a slice with this name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e897fb-64ae-474c-819f-0081dabe3893",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    slice = fablib.get_slice(slice_name)\n",
    "    print(\"You already have a slice by this name!\")\n",
    "    print(\"If you previously reserved resources, skip to the 'log in to resources' section.\")\n",
    "except:\n",
    "    print(\"You don't have a slice named %s yet.\" % slice_name)\n",
    "    print(\"Continue to the next step to make one.\")\n",
    "    slice = fablib.new_slice(name=slice_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb7466d-f545-4b9d-9eed-23e0b0eb05e7",
   "metadata": {},
   "source": [
    "We will select a random site that has sufficient resources for our experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b45dc0e-277a-4b94-949b-00256fd1e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    site_name = fablib.get_random_site()\n",
    "    if ( (fablib.resources.get_core_available(site_name) > 1.2*exp_conf['cores']) and\n",
    "        (fablib.resources.get_component_available(site_name, 'SharedNIC-ConnectX-6') > 1.2**exp_conf['nic']) ):\n",
    "        break\n",
    "\n",
    "fablib.show_site(site_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beb1d7f-5f61-47a6-9fd1-68e00de3940f",
   "metadata": {},
   "source": [
    "Then we will add hosts and network segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df45406-0765-4d24-8a2d-b98230997f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell sets up the nodes\n",
    "for n in node_conf:\n",
    "    slice.add_node(name=n['name'], site=site_name, \n",
    "                   cores=n['cores'], \n",
    "                   ram=n['ram'], \n",
    "                   disk=n['disk'], \n",
    "                   image=n['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5b7f16-7faa-48d4-87a3-b7451bc6ce9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell sets up the network segments\n",
    "for n in net_conf:\n",
    "    ifaces = [slice.get_node(node[\"name\"]).add_component(model=\"NIC_Basic\", \n",
    "                                                 name=n[\"name\"]).get_interfaces()[0] for node in n['nodes'] ]\n",
    "    slice.add_l2network(name=n[\"name\"], type='L2Bridge', interfaces=ifaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd5c7b6-6f98-4ce9-aa15-bd9c97506677",
   "metadata": {},
   "source": [
    "The following cell submits our request to the FABRIC site. The output of this cell will update automatically as the status of our request changes.\n",
    "\n",
    "-   While it is being prepared, the “State” of the slice will appear as “Configuring”.\n",
    "-   When it is ready, the “State” of the slice will change to “StableOK”.\n",
    "\n",
    "You may prefer to walk away and come back in a few minutes (for simple slices) or a few tens of minutes (for more complicated slices with many resources)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43731b1-176c-4cfa-845f-da40ee65a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c635b-7bbd-46f5-97a4-3c8ef0d69ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice.get_state()\n",
    "slice.wait_ssh(progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cca427-c64d-4feb-8860-229de727dee0",
   "metadata": {},
   "source": [
    "### Extend your slice\n",
    "\n",
    "If you don’t plan to finish an experiment in one day, you can extend your slice. The following cell extends your reservation for 7 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d51feef-886a-4543-9cb3-1669417be683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from datetime import timedelta\n",
    "\n",
    "# Set end date to 7 days from now\n",
    "end_date = (datetime.now(timezone.utc) + timedelta(days=7)).strftime(\"%Y-%m-%d %H:%M:%S %z\")\n",
    "slice.renew(end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1459cd3-3ca1-4f9b-807c-a3d51bd5f90e",
   "metadata": {},
   "source": [
    "### Configure resources\n",
    "\n",
    "Next, we will configure the resources so they are ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3337778e-6aa2-44a5-a4d8-7cb071951092",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(name=slice_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e102a8-3471-4bb4-8a8f-5de7dde38785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages\n",
    "# this will take a while and will run in background while you do other steps\n",
    "for n in node_conf:\n",
    "    if len(n['packages']):\n",
    "        node = slice.get_node(n['name'])\n",
    "        pkg = \" \".join(n['packages'])\n",
    "        node.execute_thread(\"sudo apt update; sudo DEBIAN_FRONTEND=noninteractive apt -y install %s\" % pkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec7cc05-a03b-422e-a969-868ffef33268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring interfaces up and either assign an address (if there is one) or flush address\n",
    "from ipaddress import ip_address, IPv4Address, IPv4Network\n",
    "\n",
    "for net in net_conf:\n",
    "    for n in net['nodes']:\n",
    "        if_name = n['name'] + '-' + net['name'] + '-p1'\n",
    "        iface = slice.get_interface(if_name)\n",
    "        iface.ip_link_up()\n",
    "        if n['addr']:\n",
    "            iface.ip_addr_add(addr=n['addr'], subnet=IPv4Network(net['subnet']))\n",
    "        else:\n",
    "            iface.get_node().execute(\"sudo ip addr flush dev %s\"  % iface.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadfc33d-df2d-42e5-b759-ddd716751d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all interfaces are brought up\n",
    "for iface in slice.get_interfaces():\n",
    "    iface.ip_link_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75daad8e-fbc3-4805-96f9-ffd9336f7758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a \"hosts\" file that has names and addresses of every node\n",
    "hosts_txt = [ \"%s\\t%s\" % ( n['addr'], n['name'] ) for net in net_conf  for n in net['nodes'] if type(n) is dict and n['addr']]\n",
    "for n in slice.get_nodes():\n",
    "    for h in hosts_txt:\n",
    "        n.execute(\"echo %s | sudo tee -a /etc/hosts\" % h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e84aa-7580-416d-bdaf-9b54535ae9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable IPv4 forwarding on all nodes\n",
    "for n in slice.get_nodes():\n",
    "    n.execute(\"sudo sysctl -w net.ipv4.ip_forward=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e6405-c126-4203-ad78-b8b0d108cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up static routes\n",
    "for rt in route_conf:\n",
    "    for n in rt['nodes']:\n",
    "        slice.get_node(name=n).ip_route_add(subnet=IPv4Network(rt['addr']), gateway=rt['gw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091e3ef0-665c-48f6-a23a-caf94430ca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off segmentation offload on interfaces\n",
    "for iface in slice.get_interfaces():\n",
    "    iface_name = iface.get_device_name()\n",
    "    n = iface.get_node()\n",
    "    offloads = [\"gro\", \"lro\", \"gso\", \"tso\"]\n",
    "    for offload in offloads:\n",
    "        n.execute(\"sudo ethtool -K %s %s off\" % (iface_name, offload))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f399d71-2cf7-4c66-8107-cfea41b626d2",
   "metadata": {},
   "source": [
    "### Validate base network\n",
    "\n",
    "Before we run any experiment, we should check the “base” network - before adding any emulated delay or rate limiting - and make sure that it will not be a limiting factor in the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bff55b4-370e-4a24-81b1-87994fc3115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check base delay\n",
    "_ = slice.get_node(\"sender\").execute(\"ping -c 5 receiver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a7e1b2-193b-4f70-92de-5ead31dd15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check base capacity (by sending 10 parallel flows, look at their sum throughput)\n",
    "import time\n",
    "_ = slice.get_node(\"receiver\").execute(\"iperf3 -s -1 -D\")\n",
    "time.sleep(5)\n",
    "_ = slice.get_node(\"sender\").execute(\"iperf3 -t 30 -i 10 -P 10 -c receiver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1101fbe-8d3c-4963-9da0-ef0ba01b4ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also check Linux kernel version on sender\n",
    "_ = slice.get_node(\"sender\").execute(\"uname -a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ab1ca7-4871-42fa-8f76-9a4f0341fb68",
   "metadata": {},
   "source": [
    "### Draw the network topology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5843fe6-762c-48eb-a5b3-df1c60be9510",
   "metadata": {},
   "source": [
    "The following cell will draw the network topology, for your reference. The interface name and addresses of each experiment interface will be shown on the drawing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a397f553-a2b0-40ea-955b-1141995a3a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_nets = [(n.get_name(), {'color': 'lavender'}) for n in slice.get_l2networks() ]\n",
    "l3_nets = [(n.get_name(), {'color': 'pink'}) for n in slice.get_l3networks() ]\n",
    "hosts   =   [(n.get_name(), {'color': 'lightblue'}) for n in slice.get_nodes()]\n",
    "nodes = l2_nets + l3_nets + hosts\n",
    "ifaces = [iface.toDict() for iface in slice.get_interfaces()]\n",
    "edges = [(iface['network'], iface['node'], \n",
    "          {'label': iface['physical_dev'] + '\\n' + iface['ip_addr'] + '\\n' + iface['mac']}) for iface in ifaces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d06cbf5-c583-4a28-af09-5f47ec38c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(len(nodes),len(nodes)))\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, node_shape='s',  \n",
    "        node_color=[n[1]['color'] for n in nodes], \n",
    "        node_size=[len(n[0])*400 for n in nodes],  \n",
    "        with_labels=True);\n",
    "nx.draw_networkx_edge_labels(G,pos,\n",
    "                             edge_labels=nx.get_edge_attributes(G,'label'),\n",
    "                             font_color='gray',  font_size=8, rotate=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f93f29-296e-487d-84f3-9574769df1d1",
   "metadata": {},
   "source": [
    "### Log into resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3964cc59-b1b9-45e0-8f21-3a715ad9a0e6",
   "metadata": {},
   "source": [
    "Now, we are finally ready to log in to our resources over SSH! Run the following cells, and observe the table output - you will see an SSH command for each of the resources in your topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838c7e28-ab43-405c-ab66-d9460139f0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "slice_info = [{'Name': n.get_name(), 'SSH command': n.get_ssh_command()} for n in slice.get_nodes()]\n",
    "pd.DataFrame(slice_info).set_index('Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdce8e11-fcf1-449c-9b5f-68064c41b6d9",
   "metadata": {},
   "source": [
    "Now, you can open an SSH session on any of the resources as follows:\n",
    "\n",
    "-   in Jupyter, from the menu bar, use File \\> New \\> Terminal to open a new terminal.\n",
    "-   copy an SSH command from the table, and paste it into the terminal. (Note that each SSH command is a single line, even if the display wraps the text to a second line! When you copy and paste it, paste it all together.)\n",
    "\n",
    "You can repeat this process (open several terminals) to start a session on each resource. Each terminal session will have a tab in the Jupyter environment, so that you can easily switch between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a09eaf-5a63-42fd-a679-b90f99bc7c90",
   "metadata": {},
   "source": [
    "### Configure the network capacity and delay\n",
    "\n",
    "In this section, we configure the bottleneck link to have a 40Mbps capacity and 10ms delay. We will initialize the queue size to 32 BDP (although we will change this later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce1b105-374a-4959-b7fd-d0b6e85fe3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = {'rtt': 40, 'bandwidth': 10 }\n",
    "bdp_kbyte = exp['rtt']*exp['bandwidth']/8\n",
    "\n",
    "router_node = slice.get_node(\"router\")\n",
    "router_ingress_iface = router_node.get_interface(network_name = \"net0\")\n",
    "router_ingress_name = router_ingress_iface.get_device_name()\n",
    "router_egress_iface  = router_node.get_interface(network_name = \"net1\")\n",
    "router_egress_name = router_egress_iface.get_device_name()\n",
    "\n",
    "router_node.execute(\"sudo tc qdisc del dev \" + router_ingress_name + \" root\")\n",
    "router_node.execute(\"sudo tc qdisc del dev \" + router_egress_name + \" root\")\n",
    "\n",
    "# set up RTT\n",
    "router_node.execute(\"sudo tc qdisc replace dev \" + router_ingress_name + \" root netem delay \" + str(exp['rtt']) + \"ms limit 10000\")\n",
    "# set up rate limit, buffer limit\n",
    "router_node.execute(\"sudo tc qdisc replace dev \" + router_egress_name + \" root handle 1: htb default 3\")\n",
    "router_node.execute(\"sudo tc class add dev \" + router_egress_name + \" parent 1: classid 1:3 htb rate \" + str(exp['bandwidth']) + \"Mbit\")\n",
    "router_node.execute(\"sudo tc qdisc add dev \" + router_egress_name + \" parent 1:3 bfifo limit \" + str(bdp_kbyte*32) + \"kb\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9fabd5-1df0-4c95-8e82-0d5ef455c47f",
   "metadata": {},
   "source": [
    "Then, we validate the new network setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9e49d3-78e5-4404-98ed-14dd31c653b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check base delay\n",
    "_ = slice.get_node(\"sender\").execute(\"ping -c 5 receiver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c14723d-c4d4-48d0-8cd7-8f547283c9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check base capacity (by sending 10 parallel flows, look at their sum throughput)\n",
    "import time\n",
    "_ = slice.get_node(\"receiver\").execute(\"iperf3 -s -1 -D\")\n",
    "time.sleep(5)\n",
    "_ = slice.get_node(\"sender\").execute(\"iperf3 -t 30 -i 10 -P 10 -c receiver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4234ab2f-d25b-4314-8e9c-ec502be5ca0d",
   "metadata": {},
   "source": [
    "### Reproduce Figure 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fefc62c-bd25-4fe3-a8c9-865fdafb06f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_node = slice.get_node(\"router\")\n",
    "sender_node = slice.get_node(\"sender\")\n",
    "receiver_node = slice.get_node(\"receiver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af37deb-a095-4268-916e-31902f096fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "exp_factors = { \n",
    "    'bufcap': [0.25, 0.5] + [2**n for n in range(8)],\n",
    "    #'bufcap': [0.25],\n",
    "    'duration': [240],\n",
    "    'loss_cc': ['cubic', 'reno'],\n",
    "    #'loss_cc': ['cubic'],\n",
    "    'trial': [1]\n",
    "}\n",
    "factor_names = [k for k in exp_factors]\n",
    "factor_lists = list(itertools.product(*exp_factors.values()))\n",
    "exp_lists = [dict(zip(factor_names, factor_l)) for factor_l in factor_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968ea33e-6bec-4451-9bd4-487ae14ea706",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69609c82-554c-443c-b414-9068d01be83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# make sure BBR is available\n",
    "sender_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "receiver_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "\n",
    "for exp in exp_lists:\n",
    "    print(\"Running:\",exp)\n",
    "    sender_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "    # set router buffer limit \n",
    "    router_node.execute(\"sudo tc qdisc replace dev \" + router_egress_name + \" parent 1:3 bfifo limit \" + str(bdp_kbyte*exp['bufcap']) + \"kb\")\n",
    "\n",
    "    # clean up\n",
    "    receiver_node.execute(\"sudo killall iperf3\")\n",
    "    sender_node.execute(\"sudo killall iperf3\")\n",
    "    \n",
    "    time.sleep(5) \n",
    "    \n",
    "    # start an iperf3 receiver for the BBR flow\n",
    "    receiver_node.execute_thread(\"iperf3 -s -1 -i 1 -fm --logfile fig1b_bbr_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc'] + \".txt\")\n",
    "    #receiver_node.execute(\"iperf3 -s -D -1 -i 1 -fm --logfile fig1b_bbr_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc'] + \".txt\")\n",
    "    # start an iperf3 receiver for the loss based CC flows (Cubic & Reno)\n",
    "    receiver_node.execute_thread(\"iperf3 -s -1 -i 1 -fm --logfile fig1b_\" + exp['loss_cc'] + \"_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc'] + \".txt -p 5301\")\n",
    "    #receiver_node.execute(\"iperf3 -s -D -1 -i 1 -fm --logfile fig1b_\" + exp['loss_cc'] + \"_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc'] + \".txt -p 5301\")\n",
    "\n",
    "    time.sleep(10) \n",
    "\n",
    "    # start an iperf3 sender for the BBR flow\n",
    "    sender_node.execute_thread(\"iperf3 -c receiver -fm -t \" + str(exp['duration']) + \" -C bbr \")\n",
    "    # start an iperf3 sender for the loss based CC flows (Cubic & Reno)\n",
    "    sender_node.execute_thread(\"iperf3 -c receiver -fm -t \" + str(exp['duration']) + \" -C \" + exp['loss_cc'] + \" -p 5301\")\n",
    "\n",
    "    time.sleep(exp['duration'] + 10)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc7bdca-35dd-427b-b292-44df7682e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['bufcap', 'combo', 'cc', 'goodput'])\n",
    "for exp in exp_lists:\n",
    "\n",
    "    bbr_file = \"fig1b_bbr_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc'] + \".txt\"\n",
    "    tput_bbr = receiver_node.execute(\"cat /home/ubuntu/figure1b/\" + bbr_file + \" | grep 'receiver' | awk -F '-' '{print $2}' | awk '{print $5}'\", quiet=True)\n",
    "    df_dict = {'bufcap': exp['bufcap'], 'combo': \"BBR-\" + exp['loss_cc'], 'cc': 'BBR', 'goodput': float(tput_bbr[0].strip())}\n",
    "    df = pd.concat([df, pd.DataFrame(df_dict, index=[0])], ignore_index=True)\n",
    "\n",
    "    loss_file = \"fig1b_\" + exp['loss_cc'] + \"_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc'] + \".txt\"\n",
    "    tput_loss = receiver_node.execute(\"cat /home/ubuntu/figure1b/\" + loss_file + \" | grep 'receiver' | awk -F '-' '{print $2}' | awk '{print $5}'\", quiet=True)\n",
    "    df_dict = {'bufcap': exp['bufcap'], 'combo': \"BBR-\" + exp['loss_cc'], 'cc': exp['loss_cc'], 'goodput': float(tput_loss[0].strip())}\n",
    "    df = pd.concat([df, pd.DataFrame(df_dict, index=[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fce3b9d-295a-4a36-8be9-d656e3fdd7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['buf_str'] = df['bufcap'].astype(str)\n",
    "g = sns.FacetGrid(df, row=\"combo\", legend_out=True, aspect=2);\n",
    "g = g.map(sns.lineplot, \"buf_str\", \"goodput\",  hue=df.cc, style=df.cc, markers=\"o\", markersize=6);\n",
    "g.set_axis_labels(\"Buffer size (BDP)\", \"Goodput (Mbps)\");\n",
    "g.set(ylim=(0, 10))\n",
    "g.axes.flat[0].grid(True)\n",
    "g.axes.flat[1].grid(True)\n",
    "plt.legend();\n",
    "plt.savefig(\"figure1b.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1f6f21-ed69-43e5-833a-90cbaec25d70",
   "metadata": {},
   "source": [
    "### Reproduce Figure 1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdd922c-f1ea-4aeb-935e-25325cf3eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_node = slice.get_node(\"router\")\n",
    "sender_node = slice.get_node(\"sender\")\n",
    "receiver_node = slice.get_node(\"receiver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0591f081-58af-4317-a8a7-99baf8ad76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set router buffer limit to 32 BDP\n",
    "router_node.execute(\"sudo tc qdisc replace dev \" + router_egress_name + \" parent 1:3 bfifo limit \" + str(bdp_kbyte*32) + \"kb\")\n",
    "\n",
    "# make sure BBR is available\n",
    "sender_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "\n",
    "# clean up\n",
    "receiver_node.execute(\"sudo killall iperf3\")\n",
    "receiver_node.execute(\"rm fig1c_bbr.txt\")\n",
    "receiver_node.execute(\"rm fig1c_cubic.txt\")\n",
    "\n",
    "# start an iperf3 receiver for the BBR flow\n",
    "receiver_node.execute_thread(\"iperf3 -s -1 -i 1 -fm --logfile fig1c_bbr.txt\")\n",
    "# start an iperf3 receiver for the Cubic flows\n",
    "receiver_node.execute_thread(\"iperf3 -s -1 -i 1 -fm --logfile fig1c_cubic.txt -p 5301\")\n",
    "\n",
    "time.sleep(5) \n",
    "\n",
    "# start an iperf3 sender for the BBR flow\n",
    "sender_node.execute_thread(\"iperf3 -c receiver -fm -t 300 -C bbr \")\n",
    "# start an iperf3 receiver for the Cubic flows\n",
    "sender_node.execute_thread(\"iperf3 -c receiver -fm -t 300 -C cubic -P 16 -p 5301\")\n",
    "\n",
    "time.sleep(305)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea731c3-41a9-4516-b5b9-8e17d457cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tput_bbr = receiver_node.execute(\"head --lines=-5 /home/ubuntu/figure1c/fig1c_bbr.txt | grep 'Mbits/sec' | awk -F '-' '{print $2}' | awk '{print $1\\\",\\\"$5}'\", quiet=True)\n",
    "df_bbr = pd.read_csv(StringIO(tput_bbr[0]), names = ['time','goodput'])\n",
    "\n",
    "tput_cubic = receiver_node.execute(\"head --lines=-37 /home/ubuntu/figure1c/fig1c_cubic.txt | grep 'SUM' | awk -F '-' '{print $2}' | awk '{print $1\\\",\\\"$5}'\", quiet=True)\n",
    "df_cubic = pd.read_csv(StringIO(tput_cubic[0]), names = ['time','goodput'])\n",
    "\n",
    "_ = plt.figure(figsize=(12,6))\n",
    "_ = plt.plot(df_bbr.time, df_bbr.goodput, label=\"1 BBR flow\")\n",
    "_ = plt.plot(df_cubic.time, df_cubic.goodput, label=\"Sum of 16 CUBIC flows\")\n",
    "_ = plt.legend(loc=\"upper center\", ncol=2)\n",
    "_ = plt.ylabel(\"Goodput (Mbps)\")\n",
    "_ = plt.xlabel(\"Time (s)\")\n",
    "plt.savefig(\"figure1c.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a627ac7-d58e-4f18-812e-f9eb02c72247",
   "metadata": {},
   "source": [
    "### Reproduce Figure 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4933fb-3925-4580-bc52-0c10339b0737",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_node = slice.get_node(\"router\")\n",
    "sender_node = slice.get_node(\"sender\")\n",
    "receiver_node = slice.get_node(\"receiver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecbaa8d-d36b-47c0-bf28-28f038c7e918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "exp_factors = { \n",
    "    'bufcap': [2**n for n in range(7)],\n",
    "    'duration': [660],\n",
    "    'loss_cc': ['cubic'],\n",
    "    'trial': [1]\n",
    "}\n",
    "factor_names = [k for k in exp_factors]\n",
    "factor_lists = list(itertools.product(*exp_factors.values()))\n",
    "exp_lists = [dict(zip(factor_names, factor_l)) for factor_l in factor_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bb8aa2-352a-44a7-b1af-858a13bd69bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd1c96-95f9-44be-9395-3f5223666412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# make sure BBR is available\n",
    "sender_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "receiver_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "\n",
    "for exp in exp_lists:\n",
    "    print(\"Running:\",exp)\n",
    "    sender_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "    # set router buffer limit \n",
    "    router_node.execute(\"sudo tc qdisc replace dev \" + router_egress_name + \" parent 1:3 bfifo limit \" + str(bdp_kbyte*exp['bufcap']) + \"kb\")\n",
    "\n",
    "    # clean up\n",
    "    receiver_node.execute(\"sudo killall iperf3\")\n",
    "    sender_node.execute(\"sudo killall iperf3\")\n",
    "    \n",
    "    time.sleep(5) \n",
    "    \n",
    "    # start an iperf3 receiver for the BBR flow\n",
    "    receiver_node.execute_thread(\"iperf3 -s -1 -i 1 -fm --logfile fig2a_bbr_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc'] + \".txt\")\n",
    "    # start an iperf3 receiver for the loss based CC flows (Cubic & Reno)\n",
    "    receiver_node.execute_thread(\"iperf3 -s -1 -i 1 -fm --logfile fig2a_\" + exp['loss_cc'] + \"_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc'] + \".txt -p 5301\")\n",
    "\n",
    "    time.sleep(10) \n",
    "\n",
    "    # start an iperf3 sender for the BBR flow\n",
    "    sender_node.execute_thread(\"iperf3 -c receiver -fm -t \" + str(exp['duration']) + \" -C bbr \")\n",
    "    # start an iperf3 sender for the loss based CC flows (Cubic & Reno)\n",
    "    sender_node.execute_thread(\"iperf3 -c receiver -fm -t \" + str(exp['duration']) + \" -C \" + exp['loss_cc'] + \" -p 5301\")\n",
    "\n",
    "    time.sleep(exp['duration'] + 10)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36e1785-2944-4230-b875-ce92c131fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dfs = {}\n",
    "\n",
    "for exp in exp_lists:\n",
    "\n",
    "    bbr_file = \"fig2a_bbr_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc'] + \".txt\"\n",
    "    tput_bbr =  receiver_node.execute(\"head --lines=-5 /home/ubuntu/figure2a/\"+bbr_file+\" | grep 'Mbits/sec' | awk -F '-' '{print $2}' | awk '{print $1\\\",\\\"$5}'\", quiet=True)\n",
    "    df_bbr = pd.read_csv(StringIO(tput_bbr[0]), names = ['time','goodput'])\n",
    "    experiment_key = f\"bbr_{exp['bufcap']}_{exp['loss_cc']}\"\n",
    "    experiment_dfs[experiment_key] = df_bbr\n",
    "\n",
    "\n",
    "    loss_file = \"fig2a_\" + exp['loss_cc'] + \"_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc'] + \".txt\"\n",
    "    tput_loss = receiver_node.execute(\"head --lines=-5 /home/ubuntu/figure2a/\"+loss_file+\" | grep 'Mbits/sec' | awk -F '-' '{print $2}' | awk '{print $1\\\",\\\"$5}'\", quiet=True)\n",
    "    df_loss = pd.read_csv(StringIO(tput_loss[0]), names = ['time','goodput'])\n",
    "    experiment_key = f\"loss_{exp['bufcap']}_{exp['loss_cc']}\"\n",
    "    experiment_dfs[experiment_key] = df_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8640a759-6e27-4ea2-b6ee-8e4c886574cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in experiment_dfs.items():\n",
    "    # Construct file name based on the experiment key\n",
    "    file_name = f\"{key}.csv\"\n",
    "    # Save DataFrame to CSV\n",
    "    df.to_csv(file_name, index=False)\n",
    "    print(f\"Saved {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f05419-e528-4e35-9a6c-9c497d8262c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_convergence(df, percentage_change, time_period):\n",
    "    \"\"\"\n",
    "    Find the first time instance when the throughput (goodput) does not change\n",
    "    by more than X% for T seconds.\n",
    "\n",
    "    :param df: DataFrame with 'time' and 'goodput' columns\n",
    "    :param percentage_change: The maximum allowed relative change in goodput (as a percentage)\n",
    "    :param time_period: The period of time for which we require stability (in seconds)\n",
    "    :return: The time of convergence, or None if convergence was not found\n",
    "    \"\"\"\n",
    "    # Convert percentage to a proportion\n",
    "    max_change = percentage_change / 100.0\n",
    "    \n",
    "    # Initialize variables\n",
    "    start_time = df['time'].iloc[0]\n",
    "    previous_goodput = df['goodput'].iloc[0]\n",
    "    \n",
    "    # Iterate over the DataFrame to check for periods of stability\n",
    "    for i in range(1, len(df)):\n",
    "        current_time = df['time'].iloc[i]\n",
    "        current_goodput = df['goodput'].iloc[i]\n",
    "        \n",
    "        # Calculate the relative change in goodput\n",
    "        if previous_goodput != 0:  # To avoid division by zero\n",
    "            change = abs((current_goodput - previous_goodput) / previous_goodput)\n",
    "        else:\n",
    "            change = 0\n",
    "        \n",
    "        # If the change is more than the allowed max change, reset the start time\n",
    "        if change > max_change:\n",
    "            start_time = current_time\n",
    "            previous_goodput = current_goodput\n",
    "        elif (current_time - start_time) >= time_period:\n",
    "            # If the period of stability is greater than or equal to T seconds, return the start time\n",
    "            return start_time\n",
    "    \n",
    "    # If the loop completes without returning, convergence was not found\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a1f60-5506-4a34-921e-574925c9db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_convergence(df, percentage_change, time_period):\n",
    "    \"\"\"\n",
    "    Find the first time instance when the average throughput (goodput) does not change\n",
    "    by more than X% for at least T seconds.\n",
    "\n",
    "    :param df: DataFrame with 'time' and 'goodput' columns\n",
    "    :param percentage_change: The maximum allowed relative change in goodput (as a percentage)\n",
    "    :param time_period: The period of time for which we require stability (in seconds)\n",
    "    :return: The time of convergence, or None if convergence was not found\n",
    "    \"\"\"\n",
    "    # Convert percentage to a proportion\n",
    "    max_change = percentage_change / 100.0\n",
    "\n",
    "    # Get the initial rolling average\n",
    "    rolling_avg = df['goodput'].rolling(window=time_period, min_periods=1).mean()\n",
    "\n",
    "    for i in range(time_period, len(df)):\n",
    "        # Calculate the percentage change between the current rolling average and the previous period's rolling average\n",
    "        if rolling_avg[i - time_period] != 0:  # To avoid division by zero\n",
    "            change = abs((rolling_avg[i] - rolling_avg[i - time_period]) / rolling_avg[i - time_period])\n",
    "        else:\n",
    "            change = 0\n",
    "\n",
    "        # Check if the percentage change is within the threshold\n",
    "        if change <= max_change:\n",
    "            # Return the start time of the window where convergence criteria is met\n",
    "            return df['time'].iloc[i - time_period + 1]\n",
    "\n",
    "    # If the loop completes without returning, convergence was not found\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb8b06-92ea-4a6a-bde0-d1606f160a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 0.1\n",
    "T = 120\n",
    "\n",
    "#X = 2\n",
    "#T = 20\n",
    "\n",
    "\n",
    "convergence_times = {}\n",
    "\n",
    "for key, df in experiment_dfs.items():\n",
    "    # Check if the key starts with 'bbr_'\n",
    "    if key.startswith('bbr_'):\n",
    "        \n",
    "        # Call the find_convergence function with the DataFrame\n",
    "        convergence_time = find_convergence(df, X, T)\n",
    "        \n",
    "        # Store the convergence time in the results dictionary\n",
    "        convergence_times[key] = convergence_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d958b9-35bd-417a-8b04-f669f725bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496f2819-8eaa-43d0-903a-a8bfcd41ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given queue sizes\n",
    "queue_sizes = [2**n for n in range(7)]\n",
    "\n",
    "# Extract the convergence times into a list, in the same order as queue_sizes\n",
    "times = [convergence_times.get(f'bbr_{q}_cubic', 0) for q in queue_sizes]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(np.log2(queue_sizes), times, color=(0.1, 0.3, 0.9), width=0.6)  # Adjust width for a more compact look\n",
    "plt.xlabel('Queue Size (BDP)', fontsize=14, labelpad=10)\n",
    "plt.ylabel('Convergence Time (s)', fontsize=14, labelpad=10)\n",
    "plt.title(f'Convergence Time vs Queue Size - {X}% Max Change over {T} Seconds Window ', fontsize=16, pad=20)\n",
    "plt.xticks(np.log2(queue_sizes), [str(q) for q in queue_sizes], fontsize=12)  # Ensuring proper tick label formatting\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True, linestyle='--', linewidth=0.5)  # Adjust grid style\n",
    "plt.tight_layout()  # Adjust layout to make sure everything fits without overlap\n",
    "plt.savefig(\"figure2a.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e1d39-27e4-4568-8515-521fc4213c66",
   "metadata": {},
   "source": [
    "### Reproduce Figure 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dec4ae7-375e-445e-aacf-e20e894b6997",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_node = slice.get_node(\"router\")\n",
    "sender_node = slice.get_node(\"sender\")\n",
    "receiver_node = slice.get_node(\"receiver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc077bfa-8f31-4d12-aa01-abf0f1b4151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "exp_factors = { \n",
    "    'bufcap': [2**(n+2) for n in range(5)],\n",
    "    'duration': [240, 600],\n",
    "    'loss_cc': ['cubic'],\n",
    "    'trial': [1]\n",
    "}\n",
    "factor_names = [k for k in exp_factors]\n",
    "factor_lists = list(itertools.product(*exp_factors.values()))\n",
    "exp_lists = [dict(zip(factor_names, factor_l)) for factor_l in factor_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce8a994-8b8e-4fa1-92ce-5d795345a238",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c3df5f-90d3-47cf-94fc-34556303244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# make sure BBR is available\n",
    "sender_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "receiver_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "\n",
    "for exp in exp_lists:\n",
    "    print(\"Running:\",exp)\n",
    "    sender_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "    # set router buffer limit \n",
    "    router_node.execute(\"sudo tc qdisc replace dev \" + router_egress_name + \" parent 1:3 bfifo limit \" + str(bdp_kbyte*exp['bufcap']) + \"kb\")\n",
    "\n",
    "    # clean up\n",
    "    receiver_node.execute(\"sudo killall iperf3\")\n",
    "    sender_node.execute(\"sudo killall iperf3\")\n",
    "    \n",
    "    time.sleep(5) \n",
    "    \n",
    "    # start an iperf3 receiver for the BBR flow\n",
    "    receiver_node.execute_thread(\"iperf3 -s -1 -i 1 -fm --logfile fig2b_bbr_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc']+\"_\"+ str(exp['duration'])+ \".txt\")\n",
    "    #receiver_node.execute(\"iperf3 -s -D -1 -i 1 -fm --logfile fig1b_bbr_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc'] + \".txt\")\n",
    "    # start an iperf3 receiver for the loss based CC flows (Cubic & Reno)\n",
    "    receiver_node.execute_thread(\"iperf3 -s -1 -i 1 -fm --logfile fig2b_\" + exp['loss_cc'] + \"_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc'] + \"_\"+ str(exp['duration'])+\".txt -p 5301\")\n",
    "    #receiver_node.execute(\"iperf3 -s -D -1 -i 1 -fm --logfile fig1b_\" + exp['loss_cc'] + \"_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc'] + \".txt -p 5301\")\n",
    "\n",
    "    time.sleep(10) \n",
    "\n",
    "    # start an iperf3 sender for the BBR flow\n",
    "    sender_node.execute_thread(\"iperf3 -c receiver -fm -t \" + str(exp['duration']) + \" -C bbr \")\n",
    "    # start an iperf3 sender for the loss based CC flows (Cubic & Reno)\n",
    "    sender_node.execute_thread(\"iperf3 -c receiver -fm -t \" + str(exp['duration']) + \" -C \" + exp['loss_cc'] + \" -p 5301\")\n",
    "\n",
    "    time.sleep(exp['duration'] + 10)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa90ba9-6de5-4fdb-96fd-4028afd165ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['bufcap', 'duration', 'combo', 'cc', 'goodput'])\n",
    "for exp in exp_lists:\n",
    "\n",
    "    bbr_file = \"fig2b_bbr_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc']+\"_\"+ str(exp['duration']) + \".txt\"\n",
    "    tput_bbr = receiver_node.execute(\"cat /home/ubuntu/figure2b/\" + bbr_file + \" | grep 'receiver' | awk -F '-' '{print $2}' | awk '{print $5}'\", quiet=True)\n",
    "    df_dict = {'bufcap': exp['bufcap'], 'duration': exp['duration'], 'combo': \"BBR-\" + exp['loss_cc'], 'cc': 'BBR', 'goodput': float(tput_bbr[0].strip())}\n",
    "    df = pd.concat([df, pd.DataFrame(df_dict, index=[0])], ignore_index=True)\n",
    "\n",
    "    loss_file = \"fig2b_\" + exp['loss_cc'] + \"_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc'] + \"_\"+ str(exp['duration']) + \".txt\"\n",
    "    tput_loss = receiver_node.execute(\"cat /home/ubuntu/figure2b/\" + loss_file + \" | grep 'receiver' | awk -F '-' '{print $2}' | awk '{print $5}'\", quiet=True)\n",
    "    df_dict = {'bufcap': exp['bufcap'],'duration': exp['duration'], 'combo': \"BBR-\" + exp['loss_cc'], 'cc': exp['loss_cc'], 'goodput': float(tput_loss[0].strip())}\n",
    "    df = pd.concat([df, pd.DataFrame(df_dict, index=[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2ee80-3f5a-4482-a365-08166aa4f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdcab0f-1b60-4a3f-9606-141436bbda65",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dfs = {}\n",
    "#tput_bbr =  receiver_node.execute(\"head --lines=-5 /home/ubuntu/figure2a/\"+bbr_file+\" | grep 'Mbits/sec' | awk -F '-' '{print $2}' | awk '{print $1\\\",\\\"$5}'\", quiet=True)\n",
    "\n",
    "for exp in exp_lists:\n",
    "    \n",
    "    if exp[\"duration\"] ==600:\n",
    "        bbr_file = \"fig2b_bbr_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc']+\"_\"+ str(exp['duration']) + \".txt\"\n",
    "        tput_bbr =  receiver_node.execute(\"tail -n 185 /home/ubuntu/figure2b/\"+bbr_file+\" | head -n 180 | grep 'Mbits/sec' | awk -F '-' '{print $2}' | awk '{print $1\\\",\\\"$5}'\", quiet=True)\n",
    "        #print(tput_bbr)\n",
    "        df_bbr = pd.read_csv(StringIO(tput_bbr[0]), names = ['time','goodput'])\n",
    "        average_goodput = df_bbr['goodput'].mean()\n",
    "        experiment_key = f\"bbr_{exp['bufcap']}_{exp['loss_cc']}_{exp['duration']}\"\n",
    "        experiment_dfs[experiment_key] = average_goodput  \n",
    "                                   \n",
    "                                   \n",
    "    #loss_file = \"fig2b_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc']+\"_\"+ str(exp['duration']) + \".txt\"\n",
    "    #t_loss =  receiver_node.execute(\"tail -n 185 /home/ubuntu/figure2b/\"+loss_file+\" | head -n 180 | grep 'Mbits/sec' | awk -F '-' '{print $2}' | awk '{print $1\\\",\\\"$5}'\", quiet=True)\n",
    "    #df_loss = pd.read_csv(StringIO(tput_bbr[0]), names = ['time','goodput'])\n",
    "    #average_goodput = df_bbr['goodput'].mean()\n",
    "    #experiment_key = f\"bbr_{exp['bufcap']}_{exp['loss_cc']}_{exp['duration']}\"\n",
    "    #experiment_dfs[experiment_key] = average_goodput\n",
    "\n",
    "# Assuming you want to see the results:\n",
    "print(experiment_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dd62e0-508d-487f-93ae-241fddb04ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbr_df = df[df['cc'] == 'BBR'].copy()\n",
    "\n",
    "# Convert 'duration' to a string column for labeling purposes in the plot\n",
    "bbr_df['duration_str'] = bbr_df['duration'].apply(lambda x: f'{x//60} min')\n",
    "\n",
    "# Initialize a large enough figure size for clarity\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=bbr_df, x='bufcap', y='goodput', hue='duration_str', errorbar=None)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Buffer Size (BDP)')\n",
    "plt.ylabel('Goodput (Mbps)')\n",
    "plt.title('BBR Throughput for Different Durations')\n",
    "plt.legend(title='Duration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d699c99-a3c0-42c3-b882-41b17fc74c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_data = {\n",
    "    'bufcap': [int(key.split('_')[1]) for key in experiment_dfs.keys()],\n",
    "    'goodput': list(experiment_dfs.values()),\n",
    "    'duration_str': ['After Convergence'] * len(experiment_dfs)\n",
    "}\n",
    "conv_df = pd.DataFrame(convergence_data)\n",
    "\n",
    "# Create a DataFrame from the new data\n",
    "conv_df = pd.DataFrame(convergence_data)\n",
    "\n",
    "# Concatenate this new DataFrame with the original 'bbr_df'\n",
    "bbr_df_final = pd.concat([bbr_df, conv_df], ignore_index=True)\n",
    "\n",
    "# Initialize a large enough figure size for clarity\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=bbr_df_final, x='bufcap', y='goodput', hue='duration_str', errorbar=None)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Buffer Size (BDP)')\n",
    "plt.ylabel('BBR\\'s Goodput (Mbps)')\n",
    "plt.title('BBR Throughput for Different Durations')\n",
    "plt.legend()\n",
    "plt.savefig(\"figure2b.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c397813d-2a25-4895-9554-89fd941b7dab",
   "metadata": {},
   "source": [
    "### Reproduce Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790bffe1-23c0-4ed8-aaba-6213fbdb6dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_node = slice.get_node(\"router\")\n",
    "sender_node = slice.get_node(\"sender\")\n",
    "receiver_node = slice.get_node(\"receiver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbcb6cf-7418-4d39-b3df-9b0e860ef4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "exp_factors = { \n",
    "    'bufcap': [64],\n",
    "    'duration': [240],\n",
    "    'loss_cc': ['reno','cubic'],\n",
    "    'trial': [1]\n",
    "}\n",
    "factor_names = [k for k in exp_factors]\n",
    "factor_lists = list(itertools.product(*exp_factors.values()))\n",
    "exp_lists = [dict(zip(factor_names, factor_l)) for factor_l in factor_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbe9abf-c5d0-4ee1-b9e1-f20ee098fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c504907-00bd-4515-b343-db9cb00e227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# make sure BBR is available\n",
    "sender_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "receiver_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "\n",
    "for exp in exp_lists:\n",
    "    print(\"Running:\",exp)\n",
    "    sender_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "    # set router buffer limit \n",
    "    router_node.execute(\"sudo tc qdisc replace dev \" + router_egress_name + \" parent 1:3 bfifo limit \" + str(bdp_kbyte*exp['bufcap']) + \"kb\")\n",
    "\n",
    "    # clean up\n",
    "    receiver_node.execute(\"sudo killall iperf3\")\n",
    "    sender_node.execute(\"sudo killall iperf3\")\n",
    "    \n",
    "    time.sleep(5) \n",
    "    \n",
    "    # start an iperf3 receiver for the BBR flow\n",
    "    receiver_node.execute_thread(\"iperf3 -s -1 -i 1 -fm --logfile fig3_bbr_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc'] + \".txt\")\n",
    "    # start an iperf3 receiver for the loss based CC flows (Cubic & Reno)\n",
    "    receiver_node.execute_thread(\"iperf3 -s -1 -i 1 -fm --logfile fig3_\" + exp['loss_cc'] + \"_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc'] + \".txt -p 5301\")\n",
    "\n",
    "    time.sleep(10) \n",
    "\n",
    "    # start an iperf3 sender for the BBR flow\n",
    "    sender_node.execute_thread(\"iperf3 -c receiver -fm -t \" + str(exp['duration']) + \" -C bbr \")\n",
    "    # start an iperf3 sender for the loss based CC flows (Cubic & Reno)\n",
    "    sender_node.execute_thread(\"iperf3 -c receiver -fm -t \" + str(exp['duration']) + \" -C \" + exp['loss_cc'] + \" -p 5301\")\n",
    "\n",
    "    time.sleep(exp['duration'] + 10)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccc3f7e-3208-4f2f-80e5-e6ae6c51666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dfs = {}\n",
    "\n",
    "for exp in exp_lists:\n",
    "\n",
    "    bbr_file = \"fig3_bbr_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc'] + \".txt\"\n",
    "    tput_bbr =  receiver_node.execute(\"head --lines=-5 /home/ubuntu/figure3/\"+bbr_file+\" | grep 'Mbits/sec' | awk -F '-' '{print $2}' | awk '{print $1\\\",\\\"$5}'\", quiet=True)\n",
    "    df_bbr = pd.read_csv(StringIO(tput_bbr[0]), names = ['time','goodput'])\n",
    "    experiment_key = f\"bbr_{exp['bufcap']}_{exp['loss_cc']}\"\n",
    "    experiment_dfs[experiment_key] = df_bbr\n",
    "\n",
    "\n",
    "    loss_file = \"fig3_\" + exp['loss_cc'] + \"_\" + str(exp['bufcap']) + \"_bbrV\" + exp['loss_cc'] + \".txt\"\n",
    "    tput_loss = receiver_node.execute(\"head --lines=-5 /home/ubuntu/figure3/\"+loss_file+\" | grep 'Mbits/sec' | awk -F '-' '{print $2}' | awk '{print $1\\\",\\\"$5}'\", quiet=True)\n",
    "    df_loss = pd.read_csv(StringIO(tput_loss[0]), names = ['time','goodput'])\n",
    "    experiment_key = f\"loss_{exp['bufcap']}_{exp['loss_cc']}\"\n",
    "    experiment_dfs[experiment_key] = df_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6937a5-eb88-4044-b741-65342efefded",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))  \n",
    "\n",
    "\n",
    "for exp in exp_lists:\n",
    "    bbr_key = f\"bbr_{exp['bufcap']}_{exp['loss_cc']}\"\n",
    "    loss_key = f\"loss_{exp['bufcap']}_{exp['loss_cc']}\"\n",
    "    \n",
    "    buffer_size=(bdp_kbyte*exp['bufcap']*1000)/1500\n",
    "    \n",
    "    \n",
    "    \n",
    "    bbr_queue_occupancy = (experiment_dfs[bbr_key].goodput * 0.1)*buffer_size\n",
    "    loss_queue_occupancy = (experiment_dfs[loss_key].goodput * 0.1)*buffer_size\n",
    "\n",
    "    # Check if the congestion control is CUBIC or RENO and plot in the corresponding subplot\n",
    "    if exp['loss_cc'] == 'cubic':\n",
    "        ax1.plot(experiment_dfs[bbr_key].time, bbr_queue_occupancy, label=f\"BBR\")\n",
    "        ax1.plot(experiment_dfs[loss_key].time, loss_queue_occupancy, label=f\"CUBIC\")\n",
    "        ax1.set_title(\"BBR vs CUBIC\")\n",
    "        ax1.set_xlabel(\"Time (s)\")\n",
    "        ax1.set_ylabel(\"Queue Occupancy (Packets)\")\n",
    "        ax1.legend(loc=\"upper center\", ncol=2)\n",
    "    elif exp['loss_cc'] == 'reno':\n",
    "        ax2.plot(experiment_dfs[bbr_key].time, bbr_queue_occupancy, label=f\"BBR\")\n",
    "        ax2.plot(experiment_dfs[loss_key].time, loss_queue_occupancy, label=f\"RENO\")\n",
    "        ax2.set_title(\"BBR vs RENO\")\n",
    "        ax2.set_xlabel(\"Time (s)\")\n",
    "        ax2.set_ylabel(\"Queue Occupancy (Packets)\")\n",
    "        ax2.legend(loc=\"upper center\", ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483c1420-b6de-4d56-832f-dc8beb159c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "(bdp_kbyte*exp['bufcap']*1000)/1500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003b0082-9beb-4824-af18-b0ffc4bdb067",
   "metadata": {},
   "source": [
    "### Reproduce Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310a896b-3100-4f47-9d29-12c3a8d4a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_node = slice.get_node(\"router\")\n",
    "sender_node = slice.get_node(\"sender\")\n",
    "receiver_node = slice.get_node(\"receiver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d6c748-a689-441c-9b84-c877efcdd251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "exp_factors = { \n",
    "    'bufcap': [32],\n",
    "    'duration': [600],\n",
    "    'loss_cc': ['cubic'],\n",
    "    'bbrcap':[2],\n",
    "    'trial': [1]\n",
    "}\n",
    "factor_names = [k for k in exp_factors]\n",
    "factor_lists = list(itertools.product(*exp_factors.values()))\n",
    "exp_lists = [dict(zip(factor_names, factor_l)) for factor_l in factor_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4d8e02-5de4-4da2-8ef3-ddec4fb5312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# make sure BBR is available\n",
    "sender_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "receiver_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "\n",
    "for exp in exp_lists:\n",
    "    print(\"Running:\",exp)\n",
    "    sender_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "    # set router buffer limit \n",
    "    router_node.execute(\"sudo tc qdisc replace dev \" + router_egress_name + \" parent 1:3 bfifo limit \" + str(bdp_kbyte*exp['bufcap']) + \"kb\")\n",
    "\n",
    "    # clean up\n",
    "    receiver_node.execute(\"sudo killall iperf3\")\n",
    "    sender_node.execute(\"sudo killall iperf3\")\n",
    "    \n",
    "    time.sleep(5) \n",
    "    \n",
    "    # start an iperf3 receiver for the BBR flow\n",
    "    receiver_node.execute_thread(\"iperf3 -s -1 -i 1 -fm --logfile fig5_bbr_\" + str(exp['bufcap']) +\"_\" +str(exp['bbrcap'])+ \"_bbrV\" + exp['loss_cc'] + \".txt\")\n",
    "    # start an iperf3 receiver for the loss based CC flows (Cubic & Reno)\n",
    "    receiver_node.execute_thread(\"iperf3 -s -1 -i 1 -fm --logfile fig5_\" + exp['loss_cc'] + \"_\" + str(exp['bufcap']) +\"_\" + str(exp['bbrcap']) + \"_bbrV\" + exp['loss_cc'] + \".txt -p 5301\")\n",
    "\n",
    "    time.sleep(10) \n",
    "\n",
    "    # start an iperf3 sender for the BBR flow\n",
    "    sender_node.execute_thread(\"iperf3 -c receiver -fm -t \" + str(exp['duration']) + \" -C bbr \")\n",
    "    # start an iperf3 sender for the loss based CC flows (Cubic & Reno)\n",
    "    sender_node.execute_thread(\"iperf3 -c receiver -fm -t \" + str(exp['duration']) + \" -C \" + exp['loss_cc'] + \" -p 5301\")\n",
    "\n",
    "    time.sleep(exp['duration'] + 10)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47f0d3-e98e-4ab8-a2fd-b68a9335468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dfs = {}\n",
    "\n",
    "for exp in exp_lists:\n",
    "\n",
    "    bbr_file = \"fig5_bbr_\" + str(exp['bufcap']) +\"_\" + str(exp['bbrcap']) + \"_bbrV\" + exp['loss_cc'] + \".txt\"\n",
    "    tput_bbr =  receiver_node.execute(\"head --lines=-5 /home/ubuntu/figure5/\"+bbr_file+\" | grep 'Mbits/sec' | awk -F '-' '{print $2}' | awk '{print $1\\\",\\\"$5}'\", quiet=True)\n",
    "    df_bbr = pd.read_csv(StringIO(tput_bbr[0]), names = ['time','goodput'])\n",
    "    experiment_key = f\"bbr_{exp['bufcap']}_{exp['loss_cc']}\"\n",
    "    experiment_dfs[experiment_key] = df_bbr\n",
    "\n",
    "\n",
    "    loss_file = \"fig5_\" + exp['loss_cc'] + \"_\" + str(exp['bufcap'])  +\"_\" + str(exp['bbrcap']) + \"_bbrV\" + exp['loss_cc'] + \".txt\"\n",
    "    tput_loss = receiver_node.execute(\"head --lines=-5 /home/ubuntu/figure5/\"+loss_file+\" | grep 'Mbits/sec' | awk -F '-' '{print $2}' | awk '{print $1\\\",\\\"$5}'\", quiet=True)\n",
    "    df_loss = pd.read_csv(StringIO(tput_loss[0]), names = ['time','goodput'])\n",
    "    experiment_key = f\"loss_{exp['bufcap']}_{exp['loss_cc']}\"\n",
    "    experiment_dfs[experiment_key] = df_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873af791-9016-49c7-9952-18d70dff73ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ware_model import *\n",
    "dict_model=ware_BBR_Model(40, 10, 32, 1, 600)\n",
    "bbr_model_occupancy=dict_model['simple_model_bbr_occupancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd63d3fa-a3e4-47fe-981f-a108027b07d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, (ax1, ax2) = plt.subplots(1, 1, figsize=(5, 5))  \n",
    "\n",
    "fig, ax1 =  plt.subplots(1, 1, figsize=(9, 5)) \n",
    "\n",
    "for exp in exp_lists:\n",
    "    bbr_key = f\"bbr_{exp['bufcap']}_{exp['loss_cc']}\"\n",
    "    loss_key = f\"loss_{exp['bufcap']}_{exp['loss_cc']}\"\n",
    "    \n",
    "    buffer_size=(bdp_kbyte*exp['bufcap']*1000)/1500\n",
    "    \n",
    "    \n",
    "    \n",
    "    bbr_queue_occupancy = (experiment_dfs[bbr_key].goodput * 0.1)*buffer_size\n",
    "    loss_queue_occupancy = (experiment_dfs[loss_key].goodput * 0.1)*buffer_size\n",
    "\n",
    "    # Check if the congestion control is CUBIC or RENO and plot in the corresponding subplot\n",
    "    if exp['bbrcap'] == 2:\n",
    "        ax1.plot(experiment_dfs[bbr_key].time, bbr_queue_occupancy, label=f\"BBR - 2BDP Cap\")\n",
    "        ax1.plot(experiment_dfs[loss_key].time, loss_queue_occupancy, label=f\"CUBIC\")\n",
    "        ax1.set_title(\"BBR vs CUBIC\")\n",
    "        ax1.set_xlabel(\"Time (s)\")\n",
    "        ax1.set_ylabel(\"Queue Occupancy (Packets)\")\n",
    "        ax1.axhline(y=bbr_model_occupancy, color='black', linestyle='--', label='Model')\n",
    "        ax1.legend(loc=\"upper center\", ncol=2)\n",
    "    elif exp['bbrcap'] == 4:\n",
    "        ax2.plot(experiment_dfs[bbr_key].time, bbr_queue_occupancy, label=f\"BBR - 4BDP Cap\")\n",
    "        ax2.plot(experiment_dfs[loss_key].time, loss_queue_occupancy, label=f\"CUBIC\")\n",
    "        ax2.set_title(\"BBR vs RENO\")\n",
    "        ax2.set_xlabel(\"Time (s)\")\n",
    "        ax2.set_ylabel(\"Queue Occupancy (Packets)\")\n",
    "        ax2.legend(loc=\"upper center\", ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figure5a.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c26446e-7008-4083-8c3e-e49e18bbc593",
   "metadata": {},
   "source": [
    "### Reproduce Figure 6a - 6b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1568aaf-9af6-4590-9041-86e82c1a66d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = {'rtt': 40, 'bandwidth': 15 }\n",
    "bdp_kbyte = exp['rtt']*exp['bandwidth']/8\n",
    "\n",
    "router_node = slice.get_node(\"router\")\n",
    "router_ingress_iface = router_node.get_interface(network_name = \"net0\")\n",
    "router_ingress_name = router_ingress_iface.get_device_name()\n",
    "router_egress_iface  = router_node.get_interface(network_name = \"net1\")\n",
    "router_egress_name = router_egress_iface.get_device_name()\n",
    "\n",
    "router_node.execute(\"sudo tc qdisc del dev \" + router_ingress_name + \" root\")\n",
    "router_node.execute(\"sudo tc qdisc del dev \" + router_egress_name + \" root\")\n",
    "\n",
    "# set up RTT\n",
    "router_node.execute(\"sudo tc qdisc replace dev \" + router_ingress_name + \" root netem delay \" + str(exp['rtt']) + \"ms limit 10000\")\n",
    "# set up rate limit, buffer limit\n",
    "router_node.execute(\"sudo tc qdisc replace dev \" + router_egress_name + \" root handle 1: htb default 3\")\n",
    "router_node.execute(\"sudo tc class add dev \" + router_egress_name + \" parent 1: classid 1:3 htb rate \" + str(exp['bandwidth']) + \"Mbit\")\n",
    "router_node.execute(\"sudo tc qdisc add dev \" + router_egress_name + \" parent 1:3 bfifo limit \" + str(bdp_kbyte*32) + \"kb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5d8c8-3f12-459d-909a-9709f7421642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check base delay\n",
    "_ = slice.get_node(\"sender\").execute(\"ping -c 5 receiver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e19ea8d-ef68-4d1e-b3dc-3ab2751f8de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_node = slice.get_node(\"router\")\n",
    "sender_node = slice.get_node(\"sender\")\n",
    "receiver_node = slice.get_node(\"receiver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42519141-5897-4a6f-a1bc-54c7ae902c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "exp_factors = { \n",
    "    'bufcap': [64],\n",
    "    'duration': [600],\n",
    "    'bbr_flow_number':[2**(n+1) for n in range(6)],\n",
    "    'trial': [1]\n",
    "}\n",
    "factor_names = [k for k in exp_factors]\n",
    "factor_lists = list(itertools.product(*exp_factors.values()))\n",
    "exp_lists = [dict(zip(factor_names, factor_l)) for factor_l in factor_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20050c0d-8218-40e2-95f8-9fcfcdc97b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33443f9f-3217-4edc-bf49-701cde26e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# make sure BBR is available\n",
    "sender_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "receiver_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "\n",
    "for exp in exp_lists:\n",
    "    print(\"Running:\",exp)\n",
    "    sender_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "    # set router buffer limit \n",
    "    router_node.execute(\"sudo tc qdisc replace dev \" + router_egress_name + \" parent 1:3 bfifo limit \" + str(bdp_kbyte*exp['bufcap']) + \"kb\")\n",
    "\n",
    "    # clean up\n",
    "    receiver_node.execute(\"sudo killall iperf3\")\n",
    "    sender_node.execute(\"sudo killall iperf3\")\n",
    "    \n",
    "    time.sleep(5) \n",
    "    \n",
    "    # start an iperf3 receiver for the BBR flow\n",
    "    receiver_node.execute_thread(\"iperf3 -s -1 -i 1 -fm --logfile fig6a_bbr_\" + str(exp['bufcap']) + \"_\"+ str(exp['bbr_flow_number']) + \".txt\")\n",
    "    bbr_script=\"rm -f {name}-ss.txt; start_time=$(date +%s); while true; do ss --no-header -eipn dst 10.0.1.100 | ts '%.s' | tee -a {name}-ss.txt; current_time=$(date +%s); elapsed_time=$((current_time - start_time));  if [ $elapsed_time -ge {duration} ]; then break; fi; sleep 0.1; done;\"\n",
    "\n",
    "    time.sleep(10) \n",
    "\n",
    "    # start an iperf3 sender for the BBR flow\n",
    "    sender_node.execute_thread(bbr_script.format(name=\"fig6a_bbr_\" + str(exp['bufcap']) + \"_\"+ str(exp['bbr_flow_number']), duration=exp['duration']))\n",
    "    time.sleep(1) \n",
    "    sender_node.execute_thread(\"iperf3 -c receiver -fm -t \" + str(exp['duration']) + \" -C bbr -P \"+str(exp['bbr_flow_number']))    \n",
    "    time.sleep(exp['duration'] + 10)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d59df4-b10c-4532-ab36-48f7de4adc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_script(name): \n",
    "    return f\"\"\"\n",
    "        rm -f {name}-ss.csv\n",
    "        cat {name}-ss.txt | sed -e \":a; /<->$/ {{ N; s/<->\\\\n//; ba; }}\"  | grep \"iperf3\" | grep -v \"SYN-SENT\" | grep -v \"cubic\" > {name}-ss-processed.txt \n",
    "        cat {name}-ss-processed.txt | awk '{{print $1}}' > ts-{name}.txt \n",
    "        cat {name}-ss-processed.txt | grep -oP 'bw:\\K\\d+bps' | sed 's/bps//' > bw-{name}.txt \n",
    "        cat {name}-ss-processed.txt | grep -oP '\\\\bcwnd:.*?(\\s|$)' | awk -F '[:,]' '{{print $2}}' | tr -d ' ' > cwnd-{name}.txt\n",
    "        cat {name}-ss-processed.txt | grep -oP 'mrtt:\\K\\d+\\.\\d+' | tr -d ' ' > mrtt-{name}.txt \n",
    "        cat {name}-ss-processed.txt | grep -oP '\\\\bfd=.*?(\\s|$)' | awk -F '[=,]' '{{print $2}}' | tr -d ')' | tr -d ' '   > fd-{name}.txt\n",
    "        paste ts-{name}.txt fd-{name}.txt cwnd-{name}.txt bw-{name}.txt mrtt-{name}.txt -d ',' > {name}-ss.csv\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73190089-29f5-40bf-bc0c-61a1b3dfcfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in exp_lists:\n",
    "    \n",
    "    name_bbr=\"fig6a_bbr_\" + str(exp['bufcap']) + \"_\"+ str(exp['bbr_flow_number'])\n",
    "    \n",
    "    script_bbr = generate_script(name_bbr)\n",
    "    \n",
    "    sender_node.execute(script_bbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ae2228-1974-413a-b0c6-c1cc5e1cc53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_node.upload_file(\"/home/fabric/work/BBR-Replication/analysis_with_ss.py\", f\"/home/ubuntu/analysis.py\")\n",
    "sender_node.execute(f'python3 /home/ubuntu/analysis.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc68d7ca-80f4-4b37-8748-5482f110cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_node.download_file(\"/home/fabric/work/BBR-Replication/est_bw.json\",f\"/home/ubuntu/est_bw.json\")\n",
    "sender_node.download_file(\"/home/fabric/work/BBR-Replication/est_rtt.json\",f\"/home/ubuntu/est_rtt_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832de44c-46a6-4e74-8a12-e7a5a1be6894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Initialize empty variables\n",
    "est_bw = {}\n",
    "est_rtt = {}\n",
    "\n",
    "# Directory containing JSON files\n",
    "data_directory = '/home/fabric/work/BBR-Replication/'\n",
    "\n",
    "# List of JSON files in the directory\n",
    "json_files = [f for f in os.listdir(data_directory) if f.endswith('.json')]\n",
    "\n",
    "# Load data from each JSON file and update the variables\n",
    "for file_name in json_files:\n",
    "    file_path = os.path.join(data_directory, file_name)\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Check if the file contains throughput data or srtt data based on its name\n",
    "    if 'bw' in file_name:\n",
    "        est_bw.update(data)\n",
    "    elif 'rtt' in file_name:\n",
    "        est_rtt.update(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f8801e-4f57-4d83-8dcc-201405628ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ware_model import *\n",
    "\n",
    "model_rtt_est={}\n",
    "model_inflight_est={}\n",
    "\n",
    "for exp in exp_lists:\n",
    "    dict_model=ware_BBR_Model(40, 15, exp['bufcap'], exp['bbr_flow_number'], exp['duration'])\n",
    "    name=\"fig6a_bbr_\" + str(exp['bufcap']) + \"_\"+ str(exp['bbr_flow_number'])\n",
    "    model_inflight_est[name]=dict_model['inflight_cap']\n",
    "    model_rtt_est[name]=dict_model['RTT_est_ms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de30d5-61fb-4416-b7ed-161697469d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "N=exp_factors['bbr_flow_number']\n",
    "\n",
    "model_RTT_est = [model_rtt_est['fig6a_bbr_64_' + str(n)] for n in N]\n",
    "model_inflight = [model_inflight_est['fig6a_bbr_64_' + str(n)] for n in N]\n",
    "\n",
    "\n",
    "exp_RTT_est = [est_rtt['fig6a_bbr_64_' + str(n)] for n in N]\n",
    "exp_inflight = [2*est_bw['fig6a_bbr_64_' + str(n)]*est_rtt['fig6a_bbr_64_' + str(n)]/(8*1000000) for n in N]\n",
    "\n",
    "\n",
    "\n",
    "# Create the figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "# Plot for the first subplot (RTT estimation)\n",
    "ax1.plot(N, model_RTT_est, color='orange', linestyle='-', label='Model')\n",
    "ax1.plot(N, exp_RTT_est, color='blue', linestyle='-', label='Actual')\n",
    "ax1.scatter(N, model_RTT_est, color='orange', s=50)\n",
    "ax1.scatter(N, exp_RTT_est, color='blue', s=50)\n",
    "ax1.set_xscale('log', base=2)\n",
    "ax1.set_xticks(N)\n",
    "ax1.set_xticklabels(N)\n",
    "ax1.set_title('RTT Estimation over Number of BBR Flows (Log Scale)')\n",
    "ax1.set_xlabel('Number of BBR flows')\n",
    "ax1.set_ylabel('RTT_est (ms)')\n",
    "ax1.set_ylim(0, max(np.max(model_RTT_est), np.max(exp_RTT_est)) + 5)\n",
    "ax1.legend()\n",
    "\n",
    "# Plot for the second subplot (Inflight estimation)\n",
    "ax2.plot(N, model_inflight, color='orange', linestyle='-', label='Model')\n",
    "ax2.plot(N, exp_inflight, color='blue', linestyle='-', label='Actual')\n",
    "ax2.scatter(N, model_inflight, color='orange', s=50)\n",
    "ax2.scatter(N, exp_inflight, color='blue', s=50)\n",
    "ax2.set_xscale('log', base=2)\n",
    "ax2.set_xticks(N)\n",
    "ax2.set_xticklabels(N)\n",
    "ax2.set_title('Inflight Estimation over Number of BBR Flows (Log Scale)')\n",
    "ax2.set_xlabel('Number of BBR flows')\n",
    "ax2.set_ylabel('Inflight_est (Kbytes)')\n",
    "ax2.set_ylim(0, max(model_inflight) + 5)\n",
    "ax2.legend()\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figure6.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19855cc7-995e-4f71-9eca-0ef9aeafd0bb",
   "metadata": {},
   "source": [
    "### Reproduce Figure 7 - Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db5095e-7ef6-4648-850b-b350ba2070f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ware_model import *\n",
    "\n",
    "# queue capacity as multiple of BDP\n",
    "X =  2**np.arange(0, 7)  # 1 to 64\n",
    "\n",
    "dict_model=ware_BBR_Model(40, 10, X, 1, 400)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X, dict_model[\"probe_time\"], color='gray', linestyle='dashed', label='Expected Probe Time')\n",
    "\n",
    "# Set the x-axis to a logarithmic scale with base 2\n",
    "plt.xscale('log', base=2)\n",
    "\n",
    "# Create the ticks for the x-axis manually\n",
    "plt.xticks(X, X)\n",
    "\n",
    "# Add dots at powers of 2\n",
    "plt.scatter(X, dict_model[\"probe_time\"], color='gray', s=20)\n",
    "\n",
    "# Add title and axis labels\n",
    "plt.title('Probe Time over Queue Size (Log Scale)')\n",
    "plt.xlabel('Queue Size (BDP)')\n",
    "plt.ylabel('Probe Time (s)')\n",
    "\n",
    "# Set y-axis to show full range from 0 to RTT_est\n",
    "plt.ylim(0, np.max(dict_model[\"probe_time\"])+5)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2607a360-2af1-4b25-a76a-f173c2b84211",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Reproduce Figure 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b1a5a-a42a-422f-9169-5c799f81dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_node = slice.get_node(\"router\")\n",
    "sender_node = slice.get_node(\"sender\")\n",
    "receiver_node = slice.get_node(\"receiver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2449c3-8305-41fb-9289-af88ccd7ac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_ingress_iface = router_node.get_interface(network_name = \"net0\")\n",
    "router_ingress_name = router_ingress_iface.get_device_name()\n",
    "router_egress_iface  = router_node.get_interface(network_name = \"net1\")\n",
    "router_egress_name = router_egress_iface.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cbbd55-d832-44c7-a1ec-d35faf9b2714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Base factors that remain constant across specific combinations\n",
    "exp_factors = {\n",
    "    'bufcap': [2**n for n in range(7)],\n",
    "    'duration': [1000],\n",
    "    'bbr_flow_number':[2**(n) for n in range(6)],\n",
    "    'trial': [1]\n",
    "}\n",
    "\n",
    "# List the specific combinations you need\n",
    "specific_combinations = [\n",
    "    {'rtt': 40, 'bandwidth': 10, 'loss_cc': 'cubic'},\n",
    "#    {'rtt': 40, 'bandwidth': 10, 'loss_cc': 'reno'},\n",
    "#    {'rtt': 30, 'bandwidth': 50, 'loss_cc': 'cubic'}\n",
    "]\n",
    "\n",
    "# Generate all possible combinations of the base factors\n",
    "base_combinations = list(itertools.product(*[[(k, v) for v in values] for k, values in exp_factors.items()]))\n",
    "\n",
    "# Convert list of tuples to list of dictionaries\n",
    "base_combinations = [dict(items) for items in base_combinations]\n",
    "\n",
    "# Expand the specific combinations with the base combinations\n",
    "exp_lists = [\n",
    "    {**base, **specific}\n",
    "    for base in base_combinations\n",
    "    for specific in specific_combinations\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b17c91-92c1-4d6d-b971-d9cdcf122b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# make sure BBR is available\n",
    "sender_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "receiver_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "\n",
    "for exp in exp_lists:\n",
    "    print(\"Running:\",exp)\n",
    "    sender_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "    \n",
    "    router_node.execute(\"sudo tc qdisc del dev \" + router_ingress_name + \" root\")\n",
    "    router_node.execute(\"sudo tc qdisc del dev \" + router_egress_name + \" root\")\n",
    "    router_node.execute(\"sudo tc qdisc replace dev \" + router_ingress_name + \" root netem delay \" + str(exp['rtt']) + \"ms limit 10000\")\n",
    "    router_node.execute(\"sudo tc qdisc replace dev \" + router_egress_name + \" root handle 1: htb default 3\")\n",
    "    router_node.execute(\"sudo tc class replace dev \" + router_egress_name + \" parent 1: classid 1:3 htb rate \" + str(exp['bandwidth']) + \"Mbit\")\n",
    "    \n",
    "    # set router buffer limit \n",
    "    bdp_kbyte = exp['rtt']*exp['bandwidth']/8\n",
    "    router_node.execute(\"sudo tc qdisc replace dev \" + router_egress_name + \" parent 1:3 bfifo limit \" + str(bdp_kbyte*exp['bufcap']) + \"kb\")\n",
    "    \n",
    "    # clean up\n",
    "    receiver_node.execute(\"sudo killall iperf3\")\n",
    "    sender_node.execute(\"sudo killall iperf3\")\n",
    "    \n",
    "    time.sleep(5) \n",
    "    \n",
    "    # start an iperf3 receiver for the BBR flow\n",
    "    receiver_node.execute_thread(\"iperf3 -s -1 -i 1 -fm --logfile fig8a_bbr_\" + str(exp['bufcap'])+\"_\"+str(exp['bandwidth'])+\"_\"+str(exp['rtt']) + \"_bbrV\" + exp['loss_cc'] + \"_\"+ str(exp['bbr_flow_number'])+ \".txt\")\n",
    "    \n",
    "    # start an iperf3 receiver for the loss based CC flows (Cubic & Reno)\n",
    "    receiver_node.execute_thread(\"iperf3 -s -1 -i 1 -fm --logfile fig8a_\" + exp['loss_cc'] + \"_\" + str(exp['bufcap']) +\"_\"+str(exp['bandwidth'])+\"_\"+str(exp['rtt'])+ \"_bbrV\" + exp['loss_cc'] + \"_\"+ str(exp['bbr_flow_number'])+ \".txt -p 5301\")\n",
    "\n",
    "    time.sleep(10) \n",
    "\n",
    "    # start an iperf3 sender for the BBR flow\n",
    "    sender_node.execute_thread(\"iperf3 -c receiver -fm -t \" + str(exp['duration']) + \" -C bbr -P \"+str(exp['bbr_flow_number']))\n",
    "    # start an iperf3 sender for the loss based CC flows (Cubic & Reno)\n",
    "    sender_node.execute_thread(\"iperf3 -c receiver -fm -t \" + str(exp['duration']) + \" -C \" + exp['loss_cc'] + \" -p 5301\")\n",
    "\n",
    "    time.sleep(exp['duration'] + 10)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338a9cd4-04ba-42f6-ab47-adb1533eb0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dfs = {}\n",
    "convergence_time=400\n",
    "for exp in exp_lists:\n",
    "    \n",
    "    bbr_file = \"fig8a_bbr_\" + str(exp['bufcap']) +\"_\"+str(exp['bandwidth'])+\"_\"+str(exp['rtt'])+ \"_bbrV\" + exp['loss_cc']+\"_\"+ str(exp['bbr_flow_number']) + \".txt\"\n",
    "    loss_file = \"fig8a_\" + exp['loss_cc']+\"_\"+str(exp['bufcap']) +\"_\"+str(exp['bandwidth'])+\"_\"+str(exp['rtt'])+ \"_bbrV\" + exp['loss_cc']+\"_\"+ str(exp['bbr_flow_number']) + \".txt\"\n",
    "\n",
    "    if exp['bbr_flow_number']==1:\n",
    "        tput_bbr =  receiver_node.execute(\"tail -n \" +str(convergence_time+4)+ \" /home/ubuntu/figure8a/\"+bbr_file+\" | head -n \"+str(convergence_time)+\" | grep 'Mbits/sec' | awk -F '-' '{print $2}' | awk '{print $1\\\",\\\"$5}'\", quiet=True)\n",
    "    else:\n",
    "        tput_bbr =  receiver_node.execute(\"tail -n \" +str((exp['bbr_flow_number'] + 2) * convergence_time + 2 * exp['bbr_flow_number'] + 4)+ \" /home/ubuntu/figure8a/\"+bbr_file+\" | head -n \"+str((exp['bbr_flow_number'] + 2) * convergence_time + -1)+\" | grep 'SUM' | awk -F '-' '{print $2}' | awk '{print $1\\\",\\\"$5}'\", quiet=True)\n",
    "    #print(tput_bbr)\n",
    "    tput_loss =  receiver_node.execute(\"tail -n \" +str(convergence_time+4)+ \" /home/ubuntu/figure8a/\"+loss_file+\" | head -n \"+str(convergence_time)+\" | grep 'Mbits/sec' | awk -F '-' '{print $2}' | awk '{print $1\\\",\\\"$5}'\", quiet=True)\n",
    "    \n",
    "    \n",
    "    df_bbr = pd.read_csv(StringIO(tput_bbr[0]), names = ['time','goodput'])\n",
    "    df_loss = pd.read_csv(StringIO(tput_loss[0]), names = ['time','goodput'])\n",
    "    average_goodput = df_bbr['goodput'].mean()\n",
    "    average_goodput_loss=df_loss['goodput'].mean()\n",
    "    experiment_key = f\"bbr_{exp['bufcap']}_{exp['loss_cc']}_{exp['bbr_flow_number']}_{exp['bandwidth']}_{exp['rtt']}\"\n",
    "    experiment_key_loss=f\"{exp['loss_cc']}_{exp['bufcap']}_{exp['loss_cc']}_{exp['bbr_flow_number']}_{exp['bandwidth']}_{exp['rtt']}\"\n",
    "    experiment_dfs[experiment_key] = average_goodput  \n",
    "    experiment_dfs[experiment_key_loss] = average_goodput_loss\n",
    "                                   \n",
    "        \n",
    "\n",
    "# Assuming you want to see the results:\n",
    "print(experiment_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af70427-3d5b-4e14-96c3-0fb052fabd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(experiment_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736ecb4f-9af2-4bc6-9f58-e58b6a159223",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i, NBBR in enumerate(exp_factors['bbr_flow_number'], 1):\n",
    "    dict_model = ware_BBR_Model(40, 10, np.array(exp_factors['bufcap']), NBBR, 400)\n",
    "    BBR_frac_model = dict_model['BBR_fraction']\n",
    "\n",
    "    # Plot model data\n",
    "    plt.subplot(3, 2, i)\n",
    "    plt.plot(exp_factors['bufcap'], BBR_frac_model, 's-', color='orange', label='Model')\n",
    "\n",
    "    # Prepare to plot experimental data\n",
    "    exp_data = []\n",
    "    for key, value in experiment_dfs.items():\n",
    "        parts = key.split('_')\n",
    "        if int(parts[3]) == NBBR:  # Matching the BBR flow number\n",
    "            if parts[0] == \"bbr\":\n",
    "                queue_size = int(parts[1]) \n",
    "                exp_data.append((queue_size, value/10))\n",
    "    \n",
    "    exp_data.sort()\n",
    "    exp_queue_sizes, exp_values = zip(*exp_data) if exp_data else ([], [])\n",
    "\n",
    "    # Plot experimental data\n",
    "    plt.plot(exp_queue_sizes, exp_values, 'o-', color='blue', label='Actual')\n",
    "    \n",
    "    # Subplot formatting\n",
    "    plt.title(f\"{NBBR} BBR Flow{'s' if NBBR > 1 else ''}\")\n",
    "    plt.xscale('log', base=2)\n",
    "    plt.xticks(exp_factors['bufcap'], exp_factors['bufcap'])\n",
    "    plt.xlabel('Queue Size (BDP)')\n",
    "    plt.ylabel('BBR Flows Aggregate Link Fraction')\n",
    "    plt.legend()\n",
    "\n",
    "# Adjust overall layout\n",
    "plt.suptitle('40ms × 10 Mbps, vs 1 Cubic Flow', y=0.99)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figure8a.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b42f89-e662-4c77-89d8-70aa054ea993",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i, NBBR in enumerate(exp_factors['bbr_flow_number'], 1):\n",
    "    dict_model = ware_BBR_Model(40, 10, np.array(exp_factors['bufcap']), NBBR, 400)\n",
    "    BBR_frac_model = dict_model['BBR_fraction']\n",
    "\n",
    "    plt.subplot(3, 2, i)\n",
    "    plt.plot(exp_factors['bufcap'], BBR_frac_model, 's-', color='orange', label='Model')\n",
    "\n",
    "    bbr_data = {}\n",
    "    cubic_data = {}\n",
    "    for key, value in experiment_dfs.items():\n",
    "        parts = key.split('_')\n",
    "        if parts[0] == \"bbr\" or parts[0] == \"cubic\":\n",
    "            flow_type = parts[0]\n",
    "            queue_size = int(parts[1]) \n",
    "            bbr_flow_number = int(parts[3])  # BBR flow number is now clearly identified\n",
    "\n",
    "            if bbr_flow_number == NBBR:\n",
    "                if flow_type == \"bbr\":\n",
    "                    bbr_data[queue_size] = value\n",
    "                elif flow_type == \"cubic\":\n",
    "                    cubic_data[queue_size] = value\n",
    "\n",
    "    # Compute the ratio of BBR to Cubic goodput and sort by queue size\n",
    "    ratios = [(qs, bbr_data[qs] / (bbr_data[qs]+cubic_data[qs])) for qs in bbr_data if qs in cubic_data]\n",
    "    ratios.sort()\n",
    "    exp_queue_sizes, ratio_values = zip(*ratios) if ratios else ([], [])\n",
    "\n",
    "    plt.plot(exp_queue_sizes, ratio_values, 'o-', color='blue', label='Actual')\n",
    "\n",
    "    plt.title(f\"{NBBR} BBR Flow{'s' if NBBR > 1 else ''}\")\n",
    "    plt.xscale('log', base=2)\n",
    "    plt.xticks(exp_factors['bufcap'], exp_factors['bufcap'])\n",
    "    plt.xlabel('Queue Size (BDP)')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.legend()\n",
    "\n",
    "plt.suptitle('40ms × 10 Mbps, vs 1 Cubic Flow', y=0.99)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figure8a.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b600e2-d6f5-485c-a3d2-732c6c102767",
   "metadata": {},
   "source": [
    "### Delete your slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1500ba-523c-451c-8d30-1326eeccc686",
   "metadata": {},
   "source": [
    "When you finish your experiment, you should delete your slice! The following cells deletes all the resources in your slice, freeing them for other experimenters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ab4ca-6c1c-4753-b015-dacd41cc7fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(name=slice_name)\n",
    "fablib.delete_slice(slice_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7625e7a-6d09-47c3-bca3-810e27745d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice should end up in \"Dead\" state\n",
    "# re-run this cell until you see it in \"Dead\" state\n",
    "slice.update()\n",
    "_ = slice.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
