{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e699cd97-25db-45e4-bb01-6f00fa520ff2",
   "metadata": {},
   "source": [
    "### Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3029de8f-7fce-45d0-8d4e-53433f8661e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "fablib = fablib_manager() \n",
    "conf = fablib.show_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46cb8a3-d55e-4a9a-add2-0c3907f101ac",
   "metadata": {},
   "source": [
    "### Define configuration for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4253b9a0-e3ce-44fd-95b4-f2d4becec2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_name=\"bbr-trace-validation-\" + fablib.get_bastion_username()\n",
    "try:\n",
    "    slice = fablib.get_slice(slice_name)\n",
    "    print(\"You already have a slice by this name!\")\n",
    "    print(\"If you previously reserved resources, skip to the 'log in to resources' section.\")\n",
    "except:\n",
    "    print(\"You don't have a slice named %s yet.\" % slice_name)\n",
    "    print(\"Continue to the next step to make one.\")\n",
    "    slice = fablib.new_slice(name=slice_name)\n",
    "     \n",
    "\n",
    "#slice = fablib.new_slice(name=slice_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00b93f8-7aaa-4e01-a355-1079a8fd9ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_senders = 10\n",
    "n_receivers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651947ea-3555-4dd7-be16-0532812ad1c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_requires = {'core': (n_senders+n_receivers)*4 + 4, 'nic': (n_senders + n_receivers + 1)*1}\n",
    "while True:\n",
    "    site_name = fablib.get_random_site()\n",
    "    if ( (fablib.resources.get_core_available(site_name) > 1.2*exp_requires['core']) and\n",
    "        (fablib.resources.get_component_available(site_name, 'SharedNIC-ConnectX-6') > 1.2**exp_requires['nic'])  ):\n",
    "        break\n",
    "\n",
    "fablib.show_site(site_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da1455-2f42-42cb-8448-a1781620af7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell sets up the hosts\n",
    "slice.add_node(name='router', site=site_name, cores=4, ram=32, disk=100, image='default_ubuntu_22')\n",
    "\n",
    "sender_names = [\"sender-\"+str(i) for i in range(n_senders)]\n",
    "for n in sender_names:\n",
    "    slice.add_node(name=n, site=site_name, cores=4, ram=32, disk=100, image='default_ubuntu_22')  \n",
    "\n",
    "receiver_names = [\"receiver-\"+str(i) for i in range(n_receivers)]\n",
    "for n in receiver_names:\n",
    "    slice.add_node(name=n, site=site_name, cores=4, ram=32, disk=100, image='default_ubuntu_22')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65de51fc-687c-4bc6-b1e0-46c50f9f7bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell sets up the network links\n",
    "nets = [\n",
    "    {\"name\": \"link-sender\",    \"nodes\": sender_names,  \"idx\": 0},\n",
    "    {\"name\": \"link-receiver\",  \"nodes\": receiver_names, \"idx\": 1}\n",
    "]\n",
    "\n",
    "router_iface = []\n",
    "router_iface.append(slice.get_node('router').add_component(model=\"NIC_Basic\", name='link-sender').get_interfaces()[0])\n",
    "router_iface.append(slice.get_node('router').add_component(model=\"NIC_Basic\", name='link-receiver').get_interfaces()[0])\n",
    "print(router_iface)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc10d12-7012-4952-9618-3d5537c5dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in nets:\n",
    "    ifaces = [slice.get_node(node).add_component(model=\"NIC_Basic\", name=n[\"name\"]).get_interfaces()[0] for node in n['nodes'] ] + [router_iface[n[\"idx\"]]]\n",
    "    slice.add_l2network(name=n[\"name\"], type='L2Bridge', interfaces=ifaces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b346f51-339e-4b4b-ba0e-f6eee14d8448",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice.submit(wait_timeout=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0d8680-f73a-4e2a-ad78-c11e0516dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d1ab6-e874-4ab8-a655-58b77247325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice.wait_ssh(progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e0ce67-d183-4779-bab7-e87510a65811",
   "metadata": {},
   "source": [
    "## Install BBRv2 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ffaf36-199d-4aba-b986-4bb5ad934619",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pkg_list = ['linux-headers-5.13.12_5.13.12-2_amd64.deb',\n",
    "            'linux-libc-dev_5.13.12-2_amd64.deb',\n",
    "            'linux-image-5.13.12_5.13.12-2_amd64.deb']\n",
    "\n",
    "cmd_BBRv2 =\"\"\"sudo grub-set-default \"Advanced options for Ubuntu>Ubuntu, with Linux 5.13.12\"\n",
    "sudo grub-mkconfig -o /boot/grub/grub.cfg\n",
    "sudo sed -i 's/^GRUB_DEFAULT=.*/GRUB_DEFAULT=saved/' /etc/default/grub\n",
    "sudo update-grub\n",
    "sudo reboot\"\"\"\n",
    "\n",
    "for n in sender_nodes:\n",
    "    for pkg in pkg_list:\n",
    "        n.execute(\"wget https://raw.githubusercontent.com/sdatta97/imcbbrrepro/main/setup/{packet}\".format(packet=pkg))\n",
    "    n.execute(\"sudo dpkg -i  *.deb\")\n",
    "    n.execute(cmd_BBRv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b14f1f-163a-4d72-89a3-4443637dfe66",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pkg_list = ['linux-headers-5.13.12_5.13.12-2_amd64.deb',\n",
    "            'linux-libc-dev_5.13.12-2_amd64.deb',\n",
    "            'linux-image-5.13.12_5.13.12-2_amd64.deb']\n",
    "\n",
    "cmd_BBRv2 =\"\"\"sudo grub-set-default \"Advanced options for Ubuntu>Ubuntu, with Linux 5.13.12\"\n",
    "sudo grub-mkconfig -o /boot/grub/grub.cfg\n",
    "sudo sed -i 's/^GRUB_DEFAULT=.*/GRUB_DEFAULT=saved/' /etc/default/grub\n",
    "sudo update-grub\n",
    "sudo reboot\"\"\"\n",
    "\n",
    "for n in receiver_nodes:\n",
    "    for pkg in pkg_list:\n",
    "        n.execute(\"wget https://raw.githubusercontent.com/sdatta97/imcbbrrepro/main/setup/{packet}\".format(packet=pkg))\n",
    "    n.execute(\"sudo dpkg -i  *.deb\")\n",
    "    n.execute(cmd_BBRv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab39dcb-230f-40cc-8abf-a2b343e135ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for n in sender_nodes:\n",
    "    n.execute(\"uname -a\")\n",
    "\n",
    "for n in receiver_nodes:\n",
    "    n.execute(\"uname -a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b890644c-4b2b-430b-ba40-f9bd3f05657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in sender_nodes:\n",
    "    n.execute(\"sudo modprobe tcp_bbr2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e75443-fcbf-4813-8364-710666db8397",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configure resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917897cf-bba3-4655-91ff-6d4f901c7d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(name=slice_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc26137-7544-4e69-a643-beaf52422f19",
   "metadata": {},
   "source": [
    "Bring up all of the network interfaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023e673a-af27-4a97-b4cd-b30b10d85b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iface in slice.get_interfaces():\n",
    "    iface.ip_link_up()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4078afb3-8825-4c03-b3f0-1a9e792b3380",
   "metadata": {},
   "source": [
    "Assign addresses to router interfaces and enable forwarding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5343126f-2315-462d-8d97-39fef73d1e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipaddress import ip_address, IPv4Address, IPv4Network\n",
    "\n",
    "if_sender = slice.get_interface('router-link-sender-p1')\n",
    "if_sender.ip_addr_add(addr=\"10.10.1.1\", subnet=IPv4Network(\"10.10.1.0/24\"))\n",
    "if_receive = slice.get_interface('router-link-receiver-p1')\n",
    "if_receive.ip_addr_add(addr=\"10.10.2.1\", subnet=IPv4Network(\"10.10.2.0/24\"))\n",
    "\n",
    "slice.get_node(name='router').execute(\"sudo sysctl -w net.ipv4.ip_forward=1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbbfb94-201c-4162-8c08-e14e7d522a53",
   "metadata": {},
   "source": [
    "Assign addresses to host (sender and receiver) interfaces and set up routes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28773df-3eaa-46fd-af6b-4a70c0dc4fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_senders):\n",
    "    if_name = slice.get_interface('sender-' + str(i) + '-link-sender-p1')\n",
    "    if_name.ip_addr_add(addr=\"10.10.1.1\" + str(i) , subnet=IPv4Network(\"10.10.1.0/24\"))\n",
    "    slice.get_node(name='sender-' + str(i)).ip_route_add(subnet=IPv4Network(\"10.10.2.0/24\"), gateway=\"10.10.1.1\")\n",
    "    \n",
    "for i in range(n_receivers):\n",
    "    if_name = slice.get_interface('receiver-' + str(i) + '-link-receiver-p1')\n",
    "    if_name.ip_addr_add(addr=\"10.10.2.1\" + str(i) , subnet=IPv4Network(\"10.10.2.0/24\"))\n",
    "    slice.get_node(name='receiver-' + str(i)).ip_route_add(subnet=IPv4Network(\"10.10.1.0/24\"), gateway=\"10.10.2.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902a1b20-2563-4673-a381-a90bfcc20bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off segmentation offload on interfaces\n",
    "for iface in slice.get_interfaces():\n",
    "    iface_name = iface.get_device_name()\n",
    "    n = iface.get_node()\n",
    "    offloads = [\"gro\", \"lro\", \"gso\", \"tso\"]\n",
    "    for offload in offloads:\n",
    "        n.execute(\"sudo ethtool -K %s %s off\" % (iface_name, offload))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604a50be-7231-4799-ae2d-149f6c7ba371",
   "metadata": {},
   "source": [
    "Also install `iperf3` on sender and receiver hosts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8c728f-3c4f-499a-8552-e497db67e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_nodes = [slice.get_node(name='sender-' + str(i))  for i in range(n_senders)]\n",
    "receiver_nodes = [slice.get_node(name='receiver-' + str(i))  for i in range(n_receivers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aee96fd-7552-4f52-b9be-6ee3a03b0b2d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipaddress import ip_address, IPv6Address\n",
    "for n in sender_nodes:\n",
    "    n.execute(\"sudo apt update; sudo apt -y install iperf3; sudo apt -y install python3; sudo modprobe tcp_bbr\")\n",
    "    n.execute_thread(\"sudo modprobe tcp_bbr\")\n",
    "              \n",
    "for n in receiver_nodes:\n",
    "    n.execute_thread(\"sudo apt update; sudo apt -y install iperf3\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f153c98b-f38a-4049-b58a-72f74e19fead",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for n in sender_nodes:\n",
    "    n.execute(\"sudo apt -y install python3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf6a17-abd5-431b-91df-ff2d9cc21873",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for n in sender_nodes:\n",
    "    n.execute(\"iperf3 -version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd782d1-5218-4296-9e22-e072053e9dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in sender_nodes:\n",
    "    n.execute(\"sudo apt-get update; sudo apt-get install -y python3-pip ethtool netcat moreutils \",quiet=True)\n",
    "    n.execute(\"sudo python3 -m pip install scikit-learn numpy pandas matplotlib seaborn\", quiet=True)\n",
    "    \n",
    "for n in receiver_nodes:\n",
    "    n.execute(\"sudo apt-get update; sudo apt-get install -y python3-pip ethtool netcat moreutils \",quiet=True)\n",
    "    n.execute(\"sudo python3 -m pip install scikit-learn numpy pandas matplotlib seaborn\", quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a221c-9cfc-4a2a-8b52-6e884e77a01d",
   "metadata": {},
   "source": [
    "## Draw the network topology \n",
    "\n",
    "The following cell will draw the network topology, for your reference. The interface name and addresses of each experiment interface will be shown on the drawing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86144d-bf60-433c-ae22-aff24a5b5794",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_nets = [(n.get_name(), {'color': 'lavender'}) for n in slice.get_l2networks() ]\n",
    "l3_nets = [(n.get_name(), {'color': 'pink'}) for n in slice.get_l3networks() ]\n",
    "hosts   =   [(n.get_name(), {'color': 'lightblue'}) for n in slice.get_nodes()]\n",
    "all_nodes = l2_nets + l3_nets + hosts\n",
    "ifaces = [iface.toDict() for iface in slice.get_interfaces()]\n",
    "edges = [(iface['network'], iface['node'], \n",
    "          {'label': iface['physical_dev'] + '\\n' + iface['ip_addr'] + '\\n' + iface['mac']}) for iface in ifaces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab39ad-a967-46d8-a5f2-299b5e3865a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(len(all_nodes),len(all_nodes)))\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(all_nodes)\n",
    "G.add_edges_from(edges)\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, node_shape='s',  \n",
    "        node_color=[n[1]['color'] for n in all_nodes], \n",
    "        node_size=[len(n[0])*400 for n in all_nodes],  \n",
    "        with_labels=True);\n",
    "nx.draw_networkx_edge_labels(G,pos,\n",
    "                             edge_labels=nx.get_edge_attributes(G,'label'),\n",
    "                             font_color='gray',  font_size=8, rotate=False);\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0992ed-9e98-46d4-a02d-d7d385ba145b",
   "metadata": {},
   "source": [
    "## Extend your slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ccab6a-cb8e-4a51-88a3-cffa1bde116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from datetime import timedelta\n",
    "\n",
    "# Set end date to 7 days from now\n",
    "end_date = (datetime.now(timezone.utc) + timedelta(days=7)).strftime(\"%Y-%m-%d %H:%M:%S %z\")\n",
    "slice.renew(end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff1d7f4-f9d4-4940-8d23-6d1a8587f84a",
   "metadata": {},
   "source": [
    "## Log in to hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b786a3cb-29a9-47cc-9423-0ba54706ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "slice_info = [{'Name': n.get_name(), 'SSH command': n.get_ssh_command()} for n in slice.get_nodes()]\n",
    "pd.DataFrame(slice_info).set_index('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8bfccf-a2c9-455e-8d05-5c937e7faa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_nodes = [slice.get_node(name='sender-' + str(i))  for i in range(n_senders)]\n",
    "receiver_nodes = [slice.get_node(name='receiver-' + str(i))  for i in range(n_receivers)]\n",
    "router_node = slice.get_node(name='router')\n",
    "router_ingress_iface = router_node.get_interface(network_name = \"link-sender\")\n",
    "router_egress_iface  = router_node.get_interface(network_name = \"link-receiver\")\n",
    "router_egress_name = router_egress_iface.get_device_name()\n",
    "\n",
    "sender_egress_interfaces = [slice.get_node(name='sender-' + str(i)).get_interface(network_name = \"link-sender\")  for i in range(n_senders)]\n",
    "sender_egress_names = [iface.get_device_name() for iface in sender_egress_interfaces]\n",
    "\n",
    "receiver_ingress_interfaces = [slice.get_node(name='receiver-' + str(i)).get_interface(network_name = \"link-receiver\")  for i in range(n_receivers)]\n",
    "receiver_ingress_names = [iface.get_device_name() for iface in receiver_ingress_interfaces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e08fc84-b2f9-49cf-87bc-95fc5a276a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sender_egress_interfaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26f3931-726f-4824-97a2-c350df1634f7",
   "metadata": {},
   "source": [
    "## Configure queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b1eceb-d957-46eb-8cb6-6d5ad5c62a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "btl_rate = 100 # in Mbps\n",
    "\n",
    "btl_link_delay = 10 # in ms\n",
    "\n",
    "limit = math.ceil((1*btl_rate * btl_link_delay * 10^3)/8)\n",
    "\n",
    "avpkt = 1000\n",
    "\n",
    "print(limit)\n",
    "\n",
    "print(math.ceil(limit*5/(36*avpkt)))\n",
    "\n",
    "\n",
    "router_node.execute(f\"sudo tc qdisc del dev {router_egress_name} root\")\n",
    "router_node.execute(f\"sudo tc qdisc replace dev {router_egress_name} root handle 1: htb default 3\")\n",
    "router_node.execute(f\"sudo tc class add dev {router_egress_name} parent 1: classid 1:3 htb rate {btl_rate}mbit\")\n",
    "\n",
    "router_node.execute(f\"sudo tc qdisc add dev {router_egress_name} parent 1:3 handle 3: red limit {limit} max {limit} avpkt 1000 bandwidth {btl_rate}Mbit burst 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd778d1-fb49-42ed-bce9-5d1f703d19f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "for n in sender_nodes:\n",
    "    sender_inf = n.get_interface(network_name=\"link-sender\")\n",
    "    sender_inf_name = sender_inf.get_device_name()\n",
    "    \n",
    "    sender_delay = round(random.uniform(20,30),1)\n",
    "    \n",
    "    print(sender_delay)\n",
    "    \n",
    "    n.execute(f\"sudo tc qdisc del dev {sender_inf_name} root\")\n",
    "    n.execute(f\"sudo tc qdisc add dev {sender_inf_name} root netem delay {sender_delay}ms limit 1000000\")\n",
    "    # n.execute(f\"sudo tc qdisc add dev {sender_inf_name} parent 1:1 handle 10: fq pacing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447b26f9-effa-46b3-b463-6510a56855cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in sender_nodes:\n",
    "    n.execute(\"sudo modprobe tcp_bbr\")\n",
    "    n.execute(\"sudo modprobe tcp_bbr2\")\n",
    "    \n",
    "for n in receiver_nodes:\n",
    "    n.execute(\"sudo modprobe tcp_bbr\")\n",
    "    n.execute(\"sudo modprobe tcp_bbr2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8b6b37-b634-4f4d-9776-ad69e6a3617c",
   "metadata": {},
   "source": [
    "### Execute Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944f66e1-80af-4867-a31c-0d16894f160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "receiver_nodes[0].execute(\"rm -r scherrer-exp-aggregate\")\n",
    "router_node.execute(\"rm -r scherrer-exp-aggregate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c1e75-0922-48e4-a35d-15447fb20c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set experimental parameters : generate full factorial experiment\n",
    "import itertools\n",
    "exp_factors = {\n",
    "    'rate': [100],\n",
    "    'btl_delay': [10],\n",
    "    'cca': [\"bbr-bbr\"],\n",
    "    'test_duration': [120],\n",
    "    'flows': [1],\n",
    "    'interval': [0.1],\n",
    "    'omit': [180],\n",
    "    'aqm': ['FIFO'],\n",
    "    'buffer_factor' : [1],\n",
    "    'trial': [1,2,3]\n",
    "}\n",
    "\n",
    "factor_names = [k for k in exp_factors]\n",
    "factor_lists = list(itertools.product(*exp_factors.values()))\n",
    "exp_lists = [dict(zip(factor_names, factor_l)) for factor_l in factor_lists]\n",
    "#'cca': [\"bbr-bbr\",\"bbr-bbr2\",\"bbr-cubic\",\"bbr-reno\",\"bbr2-bbr2\",\"bbr2-cubic\",\"bbr2-reno\"],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3967eab-34de-4685-882b-f3c0a9e5fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "os.remove('experiment_results.csv')\n",
    "# Create a list of header fields for the CSV file\n",
    "fields = ['rate', 'btl_delay', 'cca', 'test_duration', 'flows', 'interval', 'omit', 'aqm', 'buffer_factor', 'trial', 'jfi', 'loss_percentage', 'utilization', 'buffer_occupancy']\n",
    "\n",
    "# Write the header to the CSV file\n",
    "with open('experiment_results.csv', mode='w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fields)\n",
    "    writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a2d95d-d279-49e8-a9af-a3d5e97da254",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['rate', 'btl_delay', 'cca', 'test_duration', 'flows', 'interval', 'omit', 'aqm', 'buffer_factor', 'trial', 'jfi', 'loss_percentage', 'utilization', 'buffer_occupancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254713e7-9ff3-4a28-b815-580e619b94b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up router queue\n",
    "\n",
    "router_node.execute(f\"sudo tc qdisc del dev {router_egress_name} root\")\n",
    "router_node.execute(f\"sudo tc qdisc replace dev {router_egress_name} root handle 1: htb default 3\")\n",
    "router_node.execute(f\"sudo tc class add dev {router_egress_name} parent 1: classid 1:3 htb rate 100Mbit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c986acb4-c594-455f-a99e-458b17a47333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "router_script=\"rm queue.txt; start_time=$(date +%s); while true; do tc -p -s -d qdisc show dev {iface} | tr -d \\'\\n\\' | ts '%.s' | tee -a queue.txt; echo \\\"\\\" | tee -a queue.txt; current_time=$(date +%s); elapsed_time=$((current_time - start_time));  if [ $elapsed_time -ge {duration} ]; then break; fi; sleep 0.01; done;\"\n",
    "\n",
    "def create_directory(directory_name):\n",
    "    if not os.path.exists(directory_name):\n",
    "        os.mkdir(directory_name)\n",
    "        print(f\"Directory '{directory_name}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory_name}' already exists.\")\n",
    "        \n",
    "        \n",
    "def setup_experiment(exp):\n",
    "    directory_name = \"scherrer-exp-aggregate\"\n",
    "    create_directory(directory_name)\n",
    "\n",
    "    data_dir = os.path.join(os.getcwd(), directory_name)\n",
    "    iequal_file_out = os.path.join(data_dir, f'ieq_{\"_\".join(str(v) for v in exp.values())}.csv')\n",
    "\n",
    "    if os.path.exists(iequal_file_out):\n",
    "        print(\"Already have relevant files, skipping\")\n",
    "        return\n",
    "\n",
    "    print(\"Running experiment for exp:\", iequal_file_out)\n",
    "    \n",
    "    limit = math.ceil(((exp['buffer_factor'])*exp['rate'] * exp['btl_delay'] * 10**3)/8)\n",
    "    \n",
    "    if exp['aqm'] == 'FIFO':\n",
    "        router_node.execute(f\"sudo tc qdisc replace dev {router_egress_name} parent 1:3 handle 3: bfifo limit {limit}\")\n",
    "    if exp['aqm'] == 'RED':\n",
    "        router_node.execute(f\"sudo tc qdisc replace dev {router_egress_name} parent 1:3 handle 3: red limit {limit} avpkt 1000 bandwidth {exp['rate']}Mbit\")\n",
    "\n",
    "    # Remove existing result files from hosts\n",
    "        \n",
    "    # Set up delay on receiver interface\n",
    "    for n in receiver_nodes:\n",
    "        receiver_inf_name = receiver_ingress_names[0]\n",
    "        n.execute(f\"sudo tc qdisc del dev {receiver_inf_name} root netem\")\n",
    "        n.execute(f\"sudo tc qdisc add dev {receiver_inf_name} root netem delay {exp['btl_delay']}ms limit 1000000\")\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "def add_sender_link_delays(sender_nodes, trial):\n",
    "    for i, n in enumerate(sender_nodes):\n",
    "        sender_inf_name = sender_egress_names[i]\n",
    "\n",
    "        sender_delay = random.uniform(20, 30) # random_delays[f'Trial {trial}'][i]\n",
    "\n",
    "\n",
    "        #print(sender_delay)\n",
    "\n",
    "        n.execute(f\"sudo tc qdisc del dev {sender_inf_name} root\")\n",
    "        n.execute(f\"sudo tc qdisc add dev {sender_inf_name} root netem delay {sender_delay}ms limit 1000000\")\n",
    "        # n.execute(f\"sudo tc qdisc add dev {sender_inf_name} parent 1:1 handle 10: fq pacing\")\n",
    "\n",
    "        \n",
    "def start_servers(sender_nodes, base_port):  \n",
    "    for i,s in enumerate(sender_nodes):\n",
    "        s.execute(\"sudo killall iperf3\")\n",
    "        \n",
    "        server_port = base_port + i\n",
    "        s.execute(f\"iperf3 -s -D -p {server_port}\")\n",
    "\n",
    "def start_clients(receiver_node, sender_nodes, exp, base_port):\n",
    "    print(\"Start parallel clients on the senders\")\n",
    "    \n",
    "    r = receiver_node\n",
    "    r.execute(\"rm *.json\")\n",
    "    r.execute(\"sudo killall /home/ubuntu/iperf/src/iperf3\")\n",
    "    \n",
    "    #print(router_script.format(iface=router_egress_name, duration=exp[\"test_duration\"]))\n",
    "    \n",
    "    \n",
    "    for i, n in enumerate(sender_nodes):\n",
    "        \n",
    "        server_port = base_port + i\n",
    "        server_id = 10 + i\n",
    "        \n",
    "        cca = exp['cca'].split(\"-\")[0] if i < 5 else exp['cca'].split(\"-\")[1]\n",
    "        \n",
    "        #print(f'sleep 1; iperf3 -c 10.10.2.10 -t {exp[\"test_duration\"]} -P {exp[\"flows\"]} -C {cca} -p {server_port} -O {exp[\"omit\"]} -i {exp[\"interval\"]} -J > flow-{i}-result.json')\n",
    "\n",
    "        r.execute_thread(f'sleep 1; /home/ubuntu/iperf/src/iperf3 -c 10.10.1.{server_id} -t {exp[\"test_duration\"]} -P {exp[\"flows\"]} -C {cca} -p {server_port} -O {exp[\"omit\"]} -i {exp[\"interval\"]} -R -J > flow-{i}-result.json')\n",
    "        \n",
    "    router_node.execute_thread(router_script.format(iface=router_egress_name, duration=exp[\"test_duration\"]))\n",
    "    \n",
    "def copy_files_to_dir(exp_dir):   \n",
    "    \n",
    "    receiver_nodes[0].execute(f'mkdir -p {exp_dir} && mv *.json {exp_dir}/')\n",
    "    \n",
    "    router_node.execute(f'mkdir -p {exp_dir} && mv *.txt {exp_dir}/')\n",
    "    \n",
    "    router_node.execute(f'mkdir -p {exp_dir} && mv *.csv {exp_dir}/')\n",
    "        \n",
    "def compute_jfi(throughput):\n",
    "\n",
    "    #mean_throughput = sum(throughput) / len(throughput)\n",
    "\n",
    "    denominator = sum(t ** 2 for t in throughput)\n",
    "    \n",
    "    numerator = (sum(throughput)) ** 2\n",
    "    \n",
    "    jfi = (numerator / (len(throughput) * denominator))\n",
    "    \n",
    "    return jfi\n",
    "        \n",
    "def process_data(receiver_node, sender_nodes, exp):\n",
    "    \n",
    "    r = receiver_node\n",
    "    \n",
    "    sum_tput = 0\n",
    "    \n",
    "    pkt_loss = 0\n",
    "    \n",
    "    throughput = []\n",
    "    for i,s in enumerate(sender_nodes):\n",
    "        \n",
    "        sum_received, stderr = r.execute(f'echo $(jq \\'.end.sum_received.bits_per_second\\' \\\"flow-{i}-result.json\\\")');\n",
    "        \n",
    "        throughput.append(float(sum_received))\n",
    "        \n",
    "        retrans, stderr = r.execute(f'echo $(jq \\'.end.streams[].sender.retransmits\\' \\\"flow-{i}-result.json\\\")')\n",
    "        \n",
    "        retrans = float(retrans)\n",
    "        pkt_loss = pkt_loss + retrans\n",
    "        \n",
    "    loss_percentage = ((pkt_loss * 1500 * 8) * 100) / (sum(throughput) * exp['test_duration'])\n",
    "    \n",
    "    utilization = (sum(throughput) * 100)/ (exp['rate'] * 1000000)\n",
    "        \n",
    "    jfi = compute_jfi(throughput)\n",
    "    \n",
    "    \n",
    "    router_node.execute(\"cat queue.txt | awk '{{print $1\\\",\\\"$24$30\\\",\\\"$31}}' | tr -d 'b' | tr -d 'p' | sed 's/K/000/' | sed 's/M/000000/' > queue.csv\")\n",
    "    \n",
    "    mean_backlog, stderr = router_node.execute(\"echo $(awk -F ',' '{ total += $3; count++ } END { print total/count }' \\\"queue.csv\\\")\")\n",
    "    \n",
    "    limit = math.ceil(((exp['buffer_factor']+1)*exp['rate'] * exp['btl_delay'] * 10**3)/8)\n",
    "    \n",
    "    buffer_occupancy = (float(mean_backlog) * 100)/limit\n",
    "    \n",
    "    \n",
    "#     print(\"Jain's fairness index = \", jfi)\n",
    "    \n",
    "#     print(\"Loss percentage = \", loss_percentage)\n",
    "    \n",
    "#     print(\"Utilization = \", utilization)\n",
    "    \n",
    "#     print(\"Buffer occupancy percentage = \", buffer_occupancy)\n",
    "    \n",
    "    row = {**exp, 'jfi': jfi, 'loss_percentage': loss_percentage, 'utilization': utilization, 'buffer_occupancy': buffer_occupancy}\n",
    "    with open('experiment_results.csv', mode='a', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fields)\n",
    "        writer.writerow(row)\n",
    "\n",
    "        \n",
    "    \n",
    "for exp in exp_lists:\n",
    "    \n",
    "    setup_experiment(exp)\n",
    "    \n",
    "    add_sender_link_delays(sender_nodes, exp['trial'])\n",
    "    \n",
    "    base_port = 5201\n",
    "\n",
    "    # Start servers\n",
    "    start_servers(sender_nodes, base_port)\n",
    "    \n",
    "    # Start clients\n",
    "    start_clients(receiver_nodes[0], sender_nodes, exp, base_port)\n",
    "    \n",
    "    time.sleep(exp['test_duration'] + exp['omit'] + 10)\n",
    "    \n",
    "    \n",
    "    process_data(receiver_nodes[0], sender_nodes, exp)\n",
    "    \n",
    "    \n",
    "    # Copy files to directory\n",
    "    exp_dir = f\"scherrer-exp-aggregate/{'_'.join(str(v) for v in exp.values())}\"\n",
    "    copy_files_to_dir(exp_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5585c454-fda9-483b-9b1e-3d865a2eb5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "f'sleep 1; /home/ubuntu/iperf/src/iperf3 -c 10.10.1.10 -t {exp[\"test_duration\"]} -P {exp[\"flows\"]} -C bbr2 -p 5201 -O {exp[\"omit\"]} -i {exp[\"interval\"]} -R -J > flow-0-result.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f21e87b-37fd-421a-ba2e-6ab7d288d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "home/ubuntu/iperf/src/iperf3 -c 10.10.1.10 -t 300 -P 1 -C bbr2 -p 5201 -O 180 -i 0.1 -R -J > flow-{i}-result.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045a265b-0dea-4498-b645-a4783d8ffd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('experiment_results.csv')\n",
    "\n",
    "# Perform the operation: Multiply buffer occupancy value by (buffer_factor + 1) / buffer_factor\n",
    "df['buffer_occupancy'] = df['buffer_occupancy'] * (df['buffer_factor'] + 1) / df['buffer_factor']\n",
    "\n",
    "# Save the modified DataFrame back to a CSV file\n",
    "df.to_csv('modified_experiment_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9ac1d-fdd0-492d-9073-6648b860e63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "data = pd.read_csv('experiment_results_final.csv')\n",
    "\n",
    "# Group data by 'aqm' column\n",
    "grouped_by_aqm = data.groupby('aqm')\n",
    "\n",
    "# Define the metrics you want to plot\n",
    "metrics = ['jfi', 'loss_percentage', 'utilization', 'buffer_occupancy']\n",
    "\n",
    "# Define markers for each CCA combination\n",
    "markers = ['o', 's', '^', 'D', 'x', 'P', '*', 'v', '<', '>']\n",
    "\n",
    "# Create subplots with 2 columns\n",
    "num_metrics = len(metrics)\n",
    "num_rows = num_metrics // 2 + num_metrics % 2  # Adjust for odd number of metrics\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=2, figsize=(12, 4 * num_rows))\n",
    "\n",
    "# Flatten axes for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate through each AQM type\n",
    "for aqm, aqm_group in grouped_by_aqm:\n",
    "    # Iterate through each metric\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        ax = axes[idx]  # Select the current subplot\n",
    "        \n",
    "        ax.set_title(f\"AQM Type: {aqm} - {metric}\")\n",
    "        ax.set_xlabel('Buffer Size (in BDP)')\n",
    "        ax.set_ylabel(metric)\n",
    "        \n",
    "        # Group data by 'cca' column\n",
    "        grouped_data = aqm_group.groupby('cca')\n",
    "        \n",
    "        # Iterate through each CCA combination\n",
    "        for i, (cca, group) in enumerate(grouped_data):\n",
    "            # Group data by 'buffer_factor' and calculate the mean for each group\n",
    "            mean_data = group.groupby('buffer_factor')[metric].mean()\n",
    "            \n",
    "            # Plot the data for this CCA combination with marker\n",
    "            ax.plot(mean_data.index, mean_data.values, marker=markers[i % len(markers)], label=f'CCA {cca}')\n",
    "        \n",
    "        # Set Y limits for each metric\n",
    "        if metric == 'jfi':\n",
    "            ax.set_ylim(0, 1)\n",
    "        elif metric == 'loss_percentage':\n",
    "            ax.set_ylim(0, 25)\n",
    "        elif metric == 'utilization':\n",
    "            ax.set_ylim(90, 102)\n",
    "        elif metric == 'buffer_occupancy':\n",
    "            ax.set_ylim(0, 100)\n",
    "    \n",
    "        ax.grid(True)\n",
    "\n",
    "# Create a single legend for all subplots on the right side\n",
    "axes[0].legend(bbox_to_anchor=(1.1, 1), loc='upper left')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plots to PDF\n",
    "plt.savefig('experiment_results.pdf', format='pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8536b0fd-7ad2-4573-afe2-c7e027d0b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Read the two CSV files\n",
    "df1 = pd.read_csv('modified_experiment_results.csv')\n",
    "df2 = pd.read_csv('modified_experiment_results_2.csv')\n",
    "\n",
    "# Concatenate the DataFrames vertically\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('experiment_results_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27984e47-6383-4d63-a674-f2c8ecab13e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('experiment_results_final.csv')\n",
    "\n",
    "# Apply the condition: If utilization exceeds 100, cut it to 100\n",
    "df['utilization'] = df['utilization'].clip(upper=100)\n",
    "\n",
    "# Save the modified DataFrame back to a CSV file\n",
    "df.to_csv('experiment_results_final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f625c-ff79-4418-84a4-dc341f3c0ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Create an empty dictionary to store the sets of random numbers\n",
    "random_delays = {}\n",
    "\n",
    "# Generate and store random numbers for three trials\n",
    "for trial_number in range(1, 4):\n",
    "    random_set = [random.uniform(20, 30) for _ in range(10)]  # Generating 5 random numbers between 20 and 30\n",
    "    random_delays[f\"Trial {trial_number}\"] = random_set\n",
    "\n",
    "# Print the dictionary containing the random numbers\n",
    "print(random_delays)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
