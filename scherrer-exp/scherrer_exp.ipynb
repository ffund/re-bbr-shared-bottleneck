{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e699cd97-25db-45e4-bb01-6f00fa520ff2",
   "metadata": {},
   "source": [
    "### Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3029de8f-7fce-45d0-8d4e-53433f8661e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "fablib = fablib_manager() \n",
    "conf = fablib.show_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46cb8a3-d55e-4a9a-add2-0c3907f101ac",
   "metadata": {},
   "source": [
    "### Define configuration for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4253b9a0-e3ce-44fd-95b4-f2d4becec2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_name=\"bbr-2022-exp\" + fablib.get_bastion_username()\n",
    "try:\n",
    "    slice = fablib.get_slice(slice_name)\n",
    "    print(\"You already have a slice by this name!\")\n",
    "    print(\"If you previously reserved resources, skip to the 'log in to resources' section.\")\n",
    "except:\n",
    "    print(\"You don't have a slice named %s yet.\" % slice_name)\n",
    "    print(\"Continue to the next step to make one.\")\n",
    "    slice = fablib.new_slice(name=slice_name)\n",
    "     \n",
    "\n",
    "#slice = fablib.new_slice(name=slice_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00b93f8-7aaa-4e01-a355-1079a8fd9ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_senders = 10\n",
    "n_receivers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651947ea-3555-4dd7-be16-0532812ad1c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_requires = {'core': (n_senders+n_receivers)*4 + 4, 'nic': (n_senders + n_receivers + 1)*1}\n",
    "while True:\n",
    "    site_name = fablib.get_random_site()\n",
    "    if ( (fablib.resources.get_core_available(site_name) > 1.2*exp_requires['core']) and\n",
    "        (fablib.resources.get_component_available(site_name, 'SharedNIC-ConnectX-6') > 1.2**exp_requires['nic'])  ):\n",
    "        break\n",
    "\n",
    "fablib.show_site(site_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da1455-2f42-42cb-8448-a1781620af7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell sets up the hosts\n",
    "slice.add_node(name='router', site=site_name, cores=4, ram=32, disk=100, image='default_ubuntu_22')\n",
    "\n",
    "sender_names = [\"sender-\"+str(i) for i in range(n_senders)]\n",
    "for n in sender_names:\n",
    "    slice.add_node(name=n, site=site_name, cores=4, ram=32, disk=100, image='default_ubuntu_22')  \n",
    "\n",
    "receiver_names = [\"receiver-\"+str(i) for i in range(n_receivers)]\n",
    "for n in receiver_names:\n",
    "    slice.add_node(name=n, site=site_name, cores=4, ram=32, disk=100, image='default_ubuntu_22')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65de51fc-687c-4bc6-b1e0-46c50f9f7bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell sets up the network links\n",
    "nets = [\n",
    "    {\"name\": \"link-sender\",    \"nodes\": sender_names,  \"idx\": 0},\n",
    "    {\"name\": \"link-receiver\",  \"nodes\": receiver_names, \"idx\": 1}\n",
    "]\n",
    "\n",
    "router_iface = []\n",
    "router_iface.append(slice.get_node('router').add_component(model=\"NIC_Basic\", name='link-sender').get_interfaces()[0])\n",
    "router_iface.append(slice.get_node('router').add_component(model=\"NIC_Basic\", name='link-receiver').get_interfaces()[0])\n",
    "print(router_iface)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc10d12-7012-4952-9618-3d5537c5dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in nets:\n",
    "    ifaces = [slice.get_node(node).add_component(model=\"NIC_Basic\", name=n[\"name\"]).get_interfaces()[0] for node in n['nodes'] ] + [router_iface[n[\"idx\"]]]\n",
    "    slice.add_l2network(name=n[\"name\"], type='L2Bridge', interfaces=ifaces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b346f51-339e-4b4b-ba0e-f6eee14d8448",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice.submit(wait_timeout=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0d8680-f73a-4e2a-ad78-c11e0516dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d1ab6-e874-4ab8-a655-58b77247325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice.wait_ssh(progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4742d5c9-9f2a-4028-975f-3afa7d4fcfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_nodes = [slice.get_node(name='sender-' + str(i))  for i in range(n_senders)]\n",
    "receiver_nodes = [slice.get_node(name='receiver-' + str(i))  for i in range(n_receivers)]\n",
    "router_node = slice.get_node(name='router')\n",
    "router_ingress_iface = router_node.get_interface(network_name = \"link-sender\")\n",
    "router_egress_iface  = router_node.get_interface(network_name = \"link-receiver\")\n",
    "router_egress_name = router_egress_iface.get_device_name()\n",
    "\n",
    "sender_egress_interfaces = [slice.get_node(name='sender-' + str(i)).get_interface(network_name = \"link-sender\")  for i in range(n_senders)]\n",
    "sender_egress_names = [iface.get_device_name() for iface in sender_egress_interfaces]\n",
    "\n",
    "receiver_ingress_interfaces = [slice.get_node(name='receiver-' + str(i)).get_interface(network_name = \"link-receiver\")  for i in range(n_receivers)]\n",
    "receiver_ingress_names = [iface.get_device_name() for iface in receiver_ingress_interfaces]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e0ce67-d183-4779-bab7-e87510a65811",
   "metadata": {},
   "source": [
    "## Install BBRv2 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ffaf36-199d-4aba-b986-4bb5ad934619",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pkg_list = ['linux-headers-5.13.12_5.13.12-2_amd64.deb',\n",
    "            'linux-libc-dev_5.13.12-2_amd64.deb',\n",
    "            'linux-image-5.13.12_5.13.12-2_amd64.deb']\n",
    "\n",
    "cmd_BBRv2 =\"\"\"sudo grub-set-default \"Advanced options for Ubuntu>Ubuntu, with Linux 5.13.12\"\n",
    "sudo grub-mkconfig -o /boot/grub/grub.cfg\n",
    "sudo sed -i 's/^GRUB_DEFAULT=.*/GRUB_DEFAULT=saved/' /etc/default/grub\n",
    "sudo update-grub\n",
    "sudo reboot\"\"\"\n",
    "\n",
    "for n in sender_nodes:\n",
    "    for pkg in pkg_list:\n",
    "        n.execute(\"wget https://raw.githubusercontent.com/sdatta97/imcbbrrepro/main/setup/{packet}\".format(packet=pkg))\n",
    "    n.execute(\"sudo dpkg -i  *.deb\")\n",
    "    n.execute(cmd_BBRv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c68e7f-041c-4eec-a64f-17a258c9dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_list = ['linux-headers-5.13.12_5.13.12-2_amd64.deb',\n",
    "            'linux-libc-dev_5.13.12-2_amd64.deb',\n",
    "            'linux-image-5.13.12_5.13.12-2_amd64.deb']\n",
    "\n",
    "cmd_BBRv2 =\"\"\"sudo grub-set-default \"Advanced options for Ubuntu>Ubuntu, with Linux 5.13.12\"\n",
    "sudo grub-mkconfig -o /boot/grub/grub.cfg\n",
    "sudo sed -i 's/^GRUB_DEFAULT=.*/GRUB_DEFAULT=saved/' /etc/default/grub\n",
    "sudo update-grub\n",
    "sudo reboot\"\"\"\n",
    "\n",
    "for n in receiver_nodes:\n",
    "    for pkg in pkg_list:\n",
    "        n.execute(\"wget https://raw.githubusercontent.com/sdatta97/imcbbrrepro/main/setup/{packet}\".format(packet=pkg))\n",
    "    n.execute(\"sudo dpkg -i  *.deb\")\n",
    "    n.execute(cmd_BBRv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2621c7-29da-4cae-bf55-53f3cb43bac9",
   "metadata": {},
   "source": [
    "### Install BBRv3 Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a48a45f-4af2-45d8-8271-d6fc7093e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_list = ['linux-headers-6.4.0+_6.4.0-g6e321d1c986a-5_amd64.deb',\n",
    "            'linux-image-6.4.0+_6.4.0-g6e321d1c986a-5_amd64.deb',\n",
    "            'linux-libc-dev_6.4.0-g6e321d1c986a-5_amd64.deb']\n",
    "\n",
    "cmd_BBRv3 =\"\"\"sudo grub-set-default \"Advanced options for Ubuntu>Ubuntu, with Linux 6.4.0\"\n",
    "sudo grub-mkconfig -o /boot/grub/grub.cfg\n",
    "sudo sed -i 's/^GRUB_DEFAULT=.*/GRUB_DEFAULT=saved/' /etc/default/grub\n",
    "sudo update-grub\n",
    "sudo reboot\"\"\"\n",
    "\n",
    "for pkg in pkg_list:\n",
    "    slice.get_node(name=\"sender\").execute(\"wget https://github.com/ANONYMIZED/bbrv3-kernel/raw/main/{packet}\".format(packet=pkg))\n",
    "    slice.get_node(name=\"receiver\").execute(\"wget https://github.com/ANONYMIZED/bbrv3-kernel/raw/main/{packet}\".format(packet=pkg))\n",
    "    \n",
    "slice.get_node(name=\"sender\").execute(\"sudo dpkg -i  *.deb\")\n",
    "slice.get_node(name=\"sender\").execute(cmd_BBRv3)\n",
    "\n",
    "slice.get_node(name=\"receiver\").execute(\"sudo dpkg -i  *.deb\")\n",
    "slice.get_node(name=\"receiver\").execute(cmd_BBRv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab39dcb-230f-40cc-8abf-a2b343e135ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for n in sender_nodes:\n",
    "    n.execute(\"uname -a\")\n",
    "\n",
    "for n in receiver_nodes:\n",
    "    n.execute(\"uname -a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b890644c-4b2b-430b-ba40-f9bd3f05657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in sender_nodes:\n",
    "    n.execute(\"sudo modprobe tcp_bbr2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e75443-fcbf-4813-8364-710666db8397",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configure resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917897cf-bba3-4655-91ff-6d4f901c7d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(name=slice_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc26137-7544-4e69-a643-beaf52422f19",
   "metadata": {},
   "source": [
    "Bring up all of the network interfaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023e673a-af27-4a97-b4cd-b30b10d85b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iface in slice.get_interfaces():\n",
    "    iface.ip_link_up()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4078afb3-8825-4c03-b3f0-1a9e792b3380",
   "metadata": {},
   "source": [
    "Assign addresses to router interfaces and enable forwarding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5343126f-2315-462d-8d97-39fef73d1e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipaddress import ip_address, IPv4Address, IPv4Network\n",
    "\n",
    "if_sender = slice.get_interface('router-link-sender-p1')\n",
    "if_sender.ip_addr_add(addr=\"10.10.1.1\", subnet=IPv4Network(\"10.10.1.0/24\"))\n",
    "if_receive = slice.get_interface('router-link-receiver-p1')\n",
    "if_receive.ip_addr_add(addr=\"10.10.2.1\", subnet=IPv4Network(\"10.10.2.0/24\"))\n",
    "\n",
    "slice.get_node(name='router').execute(\"sudo sysctl -w net.ipv4.ip_forward=1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbbfb94-201c-4162-8c08-e14e7d522a53",
   "metadata": {},
   "source": [
    "Assign addresses to host (sender and receiver) interfaces and set up routes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28773df-3eaa-46fd-af6b-4a70c0dc4fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_senders):\n",
    "    if_name = slice.get_interface('sender-' + str(i) + '-link-sender-p1')\n",
    "    if_name.ip_addr_add(addr=\"10.10.1.1\" + str(i) , subnet=IPv4Network(\"10.10.1.0/24\"))\n",
    "    slice.get_node(name='sender-' + str(i)).ip_route_add(subnet=IPv4Network(\"10.10.2.0/24\"), gateway=\"10.10.1.1\")\n",
    "    \n",
    "for i in range(n_receivers):\n",
    "    if_name = slice.get_interface('receiver-' + str(i) + '-link-receiver-p1')\n",
    "    if_name.ip_addr_add(addr=\"10.10.2.1\" + str(i) , subnet=IPv4Network(\"10.10.2.0/24\"))\n",
    "    slice.get_node(name='receiver-' + str(i)).ip_route_add(subnet=IPv4Network(\"10.10.1.0/24\"), gateway=\"10.10.2.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902a1b20-2563-4673-a381-a90bfcc20bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off segmentation offload on interfaces\n",
    "for iface in slice.get_interfaces():\n",
    "    iface_name = iface.get_device_name()\n",
    "    n = iface.get_node()\n",
    "    offloads = [\"gro\", \"lro\", \"gso\", \"tso\"]\n",
    "    for offload in offloads:\n",
    "        n.execute(\"sudo ethtool -K %s %s off\" % (iface_name, offload))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604a50be-7231-4799-ae2d-149f6c7ba371",
   "metadata": {},
   "source": [
    "Also install `iperf3` on sender and receiver hosts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8c728f-3c4f-499a-8552-e497db67e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_nodes = [slice.get_node(name='sender-' + str(i))  for i in range(n_senders)]\n",
    "receiver_nodes = [slice.get_node(name='receiver-' + str(i))  for i in range(n_receivers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aee96fd-7552-4f52-b9be-6ee3a03b0b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipaddress import ip_address, IPv6Address\n",
    "for n in sender_nodes:\n",
    "    n.execute(\"sudo apt update; sudo apt -y install iperf3; sudo apt -y install python3; sudo modprobe tcp_bbr\")\n",
    "    n.execute_thread(\"sudo modprobe tcp_bbr\")\n",
    "              \n",
    "for n in receiver_nodes:\n",
    "    n.execute_thread(\"sudo apt update; sudo apt -y install iperf3\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f153c98b-f38a-4049-b58a-72f74e19fead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for n in sender_nodes:\n",
    "    n.execute(\"sudo apt -y install python3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf6a17-abd5-431b-91df-ff2d9cc21873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for n in sender_nodes:\n",
    "    n.execute(\"iperf3 -version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd782d1-5218-4296-9e22-e072053e9dcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for n in sender_nodes:\n",
    "    n.execute(\"sudo apt-get update; sudo apt-get install -y python3-pip ethtool netcat moreutils \",quiet=True)\n",
    "    n.execute(\"sudo python3 -m pip install scikit-learn numpy pandas matplotlib seaborn\", quiet=True)\n",
    "    \n",
    "for n in receiver_nodes:\n",
    "    n.execute(\"sudo apt-get update; sudo apt-get install -y python3-pip ethtool netcat moreutils \",quiet=True)\n",
    "    n.execute(\"sudo python3 -m pip install scikit-learn numpy pandas matplotlib seaborn\", quiet=True)\n",
    "    n.execute(\"sudo apt-get update; sudo apt-get install -y build-essential autoconf automake libtool; git clone https://github.com/ANONYMIZED/iperf.git; cd iperf; sudo ./bootstrap.sh; sudo ./configure; sudo make; sudo make install\")   \n",
    "\n",
    "    \n",
    "router_node.execute(\"sudo apt-get update; sudo apt-get install -y python3-pip ethtool netcat moreutils \",quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a221c-9cfc-4a2a-8b52-6e884e77a01d",
   "metadata": {},
   "source": [
    "## Draw the network topology \n",
    "\n",
    "The following cell will draw the network topology, for your reference. The interface name and addresses of each experiment interface will be shown on the drawing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86144d-bf60-433c-ae22-aff24a5b5794",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_nets = [(n.get_name(), {'color': 'lavender'}) for n in slice.get_l2networks() ]\n",
    "l3_nets = [(n.get_name(), {'color': 'pink'}) for n in slice.get_l3networks() ]\n",
    "hosts   =   [(n.get_name(), {'color': 'lightblue'}) for n in slice.get_nodes()]\n",
    "all_nodes = l2_nets + l3_nets + hosts\n",
    "ifaces = [iface.toDict() for iface in slice.get_interfaces()]\n",
    "edges = [(iface['network'], iface['node'], \n",
    "          {'label': iface['physical_dev'] + '\\n' + iface['ip_addr'] + '\\n' + iface['mac']}) for iface in ifaces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab39ad-a967-46d8-a5f2-299b5e3865a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(len(all_nodes),len(all_nodes)))\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(all_nodes)\n",
    "G.add_edges_from(edges)\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, node_shape='s',  \n",
    "        node_color=[n[1]['color'] for n in all_nodes], \n",
    "        node_size=[len(n[0])*400 for n in all_nodes],  \n",
    "        with_labels=True);\n",
    "nx.draw_networkx_edge_labels(G,pos,\n",
    "                             edge_labels=nx.get_edge_attributes(G,'label'),\n",
    "                             font_color='gray',  font_size=8, rotate=False);\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0992ed-9e98-46d4-a02d-d7d385ba145b",
   "metadata": {},
   "source": [
    "## Extend your slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ccab6a-cb8e-4a51-88a3-cffa1bde116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from datetime import timedelta\n",
    "\n",
    "# Set end date to 7 days from now\n",
    "end_date = (datetime.now(timezone.utc) + timedelta(days=7)).strftime(\"%Y-%m-%d %H:%M:%S %z\")\n",
    "slice.renew(end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff1d7f4-f9d4-4940-8d23-6d1a8587f84a",
   "metadata": {},
   "source": [
    "## Log in to hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b786a3cb-29a9-47cc-9423-0ba54706ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "slice_info = [{'Name': n.get_name(), 'SSH command': n.get_ssh_command()} for n in slice.get_nodes()]\n",
    "pd.DataFrame(slice_info).set_index('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e08fc84-b2f9-49cf-87bc-95fc5a276a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sender_egress_interfaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8b6b37-b634-4f4d-9776-ad69e6a3617c",
   "metadata": {},
   "source": [
    "### Execute Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944f66e1-80af-4867-a31c-0d16894f160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "receiver_nodes[0].execute(\"rm -r scherrer-exp-aggregate-9-seconds\")\n",
    "router_node.execute(\"rm -r scherrer-exp-aggregate-9-seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c1e75-0922-48e4-a35d-15447fb20c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set experimental parameters : generate full factorial experiment\n",
    "import itertools\n",
    "exp_factors = {\n",
    "    'rate': [100],\n",
    "    'btl_delay': [10],\n",
    "    'cca': [\"bbr-bbr\",\"bbr-bbr2\",\"bbr-cubic\",\"bbr-reno\",\"bbr2-bbr2\",\"bbr2-cubic\",\"bbr2-reno\"],\n",
    "    'test_duration': [5],\n",
    "    'flows': [1],\n",
    "    'interval': [0.1],\n",
    "    'omit': [4],\n",
    "    'aqm': ['FIFO'],\n",
    "    'buffer_factor' : [1,2,3,4,5,6,7,8,16,32,64],\n",
    "    'trial': [1,2,3]\n",
    "}\n",
    "\n",
    "factor_names = [k for k in exp_factors]\n",
    "factor_lists = list(itertools.product(*exp_factors.values()))\n",
    "exp_lists = [dict(zip(factor_names, factor_l)) for factor_l in factor_lists]\n",
    "#'cca': [\"bbr-bbr\",\"bbr-bbr2\",\"bbr-cubic\",\"bbr-reno\",\"bbr2-bbr2\",\"bbr2-cubic\",\"bbr2-reno\"],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3967eab-34de-4685-882b-f3c0a9e5fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "os.remove('experiment_results.csv')\n",
    "# Create a list of header fields for the CSV file\n",
    "fields = ['rate', 'btl_delay', 'cca', 'test_duration', 'flows', 'interval', 'omit', 'aqm', 'buffer_factor', 'trial', 'jfi', 'loss_percentage', 'utilization', 'buffer_occupancy']\n",
    "\n",
    "# Write the header to the CSV file\n",
    "with open('experiment_results.csv', mode='w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fields)\n",
    "    writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a2d95d-d279-49e8-a9af-a3d5e97da254",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['rate', 'btl_delay', 'cca', 'test_duration', 'flows', 'interval', 'omit', 'aqm', 'buffer_factor', 'trial', 'jfi', 'loss_percentage', 'utilization', 'buffer_occupancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254713e7-9ff3-4a28-b815-580e619b94b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up router queue\n",
    "\n",
    "router_node.execute(f\"sudo tc qdisc del dev {router_egress_name} root\")\n",
    "router_node.execute(f\"sudo tc qdisc replace dev {router_egress_name} root handle 1: htb default 3\")\n",
    "router_node.execute(f\"sudo tc class add dev {router_egress_name} parent 1: classid 1:3 htb rate 100Mbit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b955b6-868e-46d1-b60a-99cce9c03c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in sender_nodes:\n",
    "    n.execute(\"sudo modprobe tcp_bbr2\")\n",
    "    n.execute(\"sudo modprobe tcp_bbr\")\n",
    "    \n",
    "for n in receiver_nodes:\n",
    "    n.execute(\"sudo modprobe tcp_bbr2\")\n",
    "    n.execute(\"sudo modprobe tcp_bbr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c986acb4-c594-455f-a99e-458b17a47333",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "router_script=\"sleep 4; rm queue.txt; start_time=$(date +%s); while true; do tc -p -s -d qdisc show dev {iface} | tr -d \\'\\n\\' | ts '%.s' | tee -a queue.txt; echo \\\"\\\" | tee -a queue.txt; current_time=$(date +%s); elapsed_time=$((current_time - start_time));  if [ $elapsed_time -ge {duration} ]; then break; fi; sleep 0.01; done;\"\n",
    "\n",
    "def create_directory(directory_name):\n",
    "    if not os.path.exists(directory_name):\n",
    "        os.mkdir(directory_name)\n",
    "        print(f\"Directory '{directory_name}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory_name}' already exists.\")\n",
    "        \n",
    "        \n",
    "def setup_experiment(exp):\n",
    "    directory_name = \"scherrer-exp-aggregate\"\n",
    "    create_directory(directory_name)\n",
    "\n",
    "    data_dir = os.path.join(os.getcwd(), directory_name)\n",
    "    iequal_file_out = os.path.join(data_dir, f'ieq_{\"_\".join(str(v) for v in exp.values())}.csv')\n",
    "\n",
    "    if os.path.exists(iequal_file_out):\n",
    "        print(\"Already have relevant files, skipping\")\n",
    "        return\n",
    "\n",
    "    print(\"Running experiment for exp:\", iequal_file_out)\n",
    "    \n",
    "    limit = math.ceil(((exp['buffer_factor'])*exp['rate'] * exp['btl_delay'] * 10**3)/8)\n",
    "    \n",
    "    if exp['aqm'] == 'FIFO':\n",
    "        router_node.execute(f\"sudo tc qdisc replace dev {router_egress_name} parent 1:3 handle 3: bfifo limit {limit}\")\n",
    "    if exp['aqm'] == 'RED':\n",
    "        router_node.execute(f\"sudo tc qdisc replace dev {router_egress_name} parent 1:3 handle 3: red limit {limit} avpkt 1000 bandwidth {exp['rate']}Mbit\")\n",
    "\n",
    "    # Remove existing result files from hosts\n",
    "        \n",
    "    # Set up delay on receiver interface\n",
    "    for n in receiver_nodes:\n",
    "        receiver_inf_name = receiver_ingress_names[0]\n",
    "        n.execute(f\"sudo tc qdisc del dev {receiver_inf_name} root netem\")\n",
    "        n.execute(f\"sudo tc qdisc add dev {receiver_inf_name} root netem delay {exp['btl_delay']}ms limit 1000000\")\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "def add_sender_link_delays(sender_nodes, trial):\n",
    "    for i, n in enumerate(sender_nodes):\n",
    "        sender_inf_name = sender_egress_names[i]\n",
    "\n",
    "        sender_delay = random.uniform(20, 30) # random_delays[f'Trial {trial}'][i]\n",
    "\n",
    "\n",
    "        #print(sender_delay)\n",
    "\n",
    "        n.execute(f\"sudo tc qdisc del dev {sender_inf_name} root\")\n",
    "        n.execute(f\"sudo tc qdisc add dev {sender_inf_name} root netem delay {sender_delay}ms limit 1000000\")\n",
    "        # n.execute(f\"sudo tc qdisc add dev {sender_inf_name} parent 1:1 handle 10: fq pacing\")\n",
    "\n",
    "        \n",
    "def start_servers(sender_nodes, base_port):  \n",
    "    for i,s in enumerate(sender_nodes):\n",
    "        s.execute(\"sudo killall iperf3\")\n",
    "        \n",
    "        server_port = base_port + i\n",
    "        s.execute(f\"iperf3 -s -D -p {server_port}\")\n",
    "\n",
    "def start_clients(receiver_node, sender_nodes, exp, base_port):\n",
    "    print(\"Start parallel clients on the senders\")\n",
    "    \n",
    "    r = receiver_node\n",
    "    r.execute(\"rm *.json\")\n",
    "    r.execute(\"sudo killall /home/ubuntu/iperf/src/iperf3\")\n",
    "    \n",
    "    #print(router_script.format(iface=router_egress_name, duration=exp[\"test_duration\"]))\n",
    "    \n",
    "    \n",
    "    for i, n in enumerate(sender_nodes):\n",
    "        \n",
    "        server_port = base_port + i\n",
    "        server_id = 10 + i\n",
    "        \n",
    "        cca = exp['cca'].split(\"-\")[0] if i < 5 else exp['cca'].split(\"-\")[1]\n",
    "        \n",
    "        #print(f'sleep 1; iperf3 -c 10.10.2.10 -t {exp[\"test_duration\"]} -P {exp[\"flows\"]} -C {cca} -p {server_port} -O {exp[\"omit\"]} -i {exp[\"interval\"]} -J > flow-{i}-result.json')\n",
    "\n",
    "        r.execute_thread(f'sleep 1; /home/ubuntu/iperf/src/iperf3 -c 10.10.1.{server_id} -t {exp[\"test_duration\"]} -P {exp[\"flows\"]} -C {cca} -p {server_port} -O {exp[\"omit\"]} -i {exp[\"interval\"]} -R -J > flow-{i}-result.json')\n",
    "        \n",
    "    router_node.execute_thread(router_script.format(iface=router_egress_name, duration=exp[\"test_duration\"]))\n",
    "    \n",
    "def copy_files_to_dir(exp_dir):   \n",
    "    \n",
    "    receiver_nodes[0].execute(f'mkdir -p {exp_dir} && mv *.json {exp_dir}/')\n",
    "    \n",
    "    router_node.execute(f'mkdir -p {exp_dir} && mv *.txt {exp_dir}/')\n",
    "    \n",
    "    router_node.execute(f'mkdir -p {exp_dir} && mv *.csv {exp_dir}/')\n",
    "        \n",
    "def compute_jfi(throughput):\n",
    "\n",
    "    #mean_throughput = sum(throughput) / len(throughput)\n",
    "\n",
    "    denominator = sum(t ** 2 for t in throughput)\n",
    "    \n",
    "    numerator = (sum(throughput)) ** 2\n",
    "    \n",
    "    jfi = (numerator / (len(throughput) * denominator))\n",
    "    \n",
    "    return jfi\n",
    "        \n",
    "def process_data(receiver_node, sender_nodes, exp):\n",
    "    \n",
    "    r = receiver_node\n",
    "    \n",
    "    sum_tput = 0\n",
    "    \n",
    "    pkt_loss = 0\n",
    "    \n",
    "    throughput = []\n",
    "    for i,s in enumerate(sender_nodes):\n",
    "        \n",
    "        sum_received, stderr = r.execute(f'echo $(jq \\'.end.sum_received.bits_per_second\\' \\\"flow-{i}-result.json\\\")');\n",
    "        \n",
    "        throughput.append(float(sum_received))\n",
    "        \n",
    "        retrans, stderr = r.execute(f'echo $(jq \\'.end.streams[].sender.retransmits\\' \\\"flow-{i}-result.json\\\")');\n",
    "        \n",
    "        retrans = float(retrans)\n",
    "        pkt_loss = pkt_loss + retrans\n",
    "        \n",
    "    loss_percentage = ((pkt_loss * 1500 * 8) * 100) / (sum(throughput) * exp['test_duration'])\n",
    "    \n",
    "    utilization = (sum(throughput) * 100)/ (exp['rate'] * 1000000)\n",
    "        \n",
    "    jfi = compute_jfi(throughput)\n",
    "    \n",
    "    \n",
    "    router_node.execute(\"cat queue.txt | awk '{{print $1\\\",\\\"$24$30\\\",\\\"$31}}' | tr -d 'b' | tr -d 'p' | sed 's/K/000/' | sed 's/M/000000/' > queue.csv\")\n",
    "    \n",
    "    mean_backlog, stderr = router_node.execute(\"echo $(awk -F ',' '{ total += $3; count++ } END { print total/count }' \\\"queue.csv\\\")\");\n",
    "    \n",
    "    limit = math.ceil(((exp['buffer_factor'])*exp['rate'] * exp['btl_delay'] * 10**3)/8)\n",
    "    \n",
    "    buffer_occupancy = (float(mean_backlog) * 100)/limit\n",
    "    \n",
    "    \n",
    "#     print(\"Jain's fairness index = \", jfi)\n",
    "    \n",
    "#     print(\"Loss percentage = \", loss_percentage)\n",
    "    \n",
    "#     print(\"Utilization = \", utilization)\n",
    "    \n",
    "#     print(\"Buffer occupancy percentage = \", buffer_occupancy)\n",
    "    \n",
    "    row = {**exp, 'jfi': jfi, 'loss_percentage': loss_percentage, 'utilization': utilization, 'buffer_occupancy': buffer_occupancy}\n",
    "    with open('experiment_results.csv', mode='a', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fields)\n",
    "        writer.writerow(row)\n",
    "\n",
    "        \n",
    "    \n",
    "for exp in exp_lists:\n",
    "    \n",
    "    setup_experiment(exp)\n",
    "    \n",
    "    add_sender_link_delays(sender_nodes, exp['trial'])\n",
    "    \n",
    "    base_port = 5201\n",
    "\n",
    "    # Start servers\n",
    "    start_servers(sender_nodes, base_port)\n",
    "    \n",
    "    # Start clients\n",
    "    start_clients(receiver_nodes[0], sender_nodes, exp, base_port)\n",
    "    \n",
    "    time.sleep(exp['test_duration'] + exp['omit'] + 5)\n",
    "    \n",
    "    \n",
    "    process_data(receiver_nodes[0], sender_nodes, exp)\n",
    "    \n",
    "    \n",
    "    # Copy files to directory\n",
    "    exp_dir = f\"scherrer-exp-aggregate/{'_'.join(str(v) for v in exp.values())}\"\n",
    "    copy_files_to_dir(exp_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9ac1d-fdd0-492d-9073-6648b860e63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "data = pd.read_csv('experiment_results.csv')\n",
    "\n",
    "# Group data by 'aqm' column\n",
    "grouped_by_aqm = data.groupby('aqm')\n",
    "\n",
    "# Define the metrics you want to plot\n",
    "metrics = ['jfi', 'loss_percentage', 'utilization', 'buffer_occupancy']\n",
    "\n",
    "# Define markers for each CCA combination\n",
    "markers = ['o', 's', '^', 'D', 'x', 'P', '*', 'v', '<', '>']\n",
    "\n",
    "# Create subplots with 2 columns\n",
    "num_metrics = len(metrics)\n",
    "num_rows = num_metrics // 2 + num_metrics % 2  # Adjust for odd number of metrics\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=2, figsize=(12, 4 * num_rows))\n",
    "\n",
    "# Flatten axes for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "x_ticks = [1, 2, 3, 4, 5, 6, 7, 8, 16, 32, 64]\n",
    "\n",
    "# Iterate through each AQM type\n",
    "for aqm, aqm_group in grouped_by_aqm:\n",
    "    # Iterate through each metric\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        ax = axes[idx]  # Select the current subplot\n",
    "        \n",
    "        ax.set_title(f\"AQM Type: {aqm} - {metric}\")\n",
    "        ax.set_xscale('log', base=2)\n",
    "        ax.set_xticks(x_ticks)\n",
    "        ax.set_xticklabels([str(x) for x in x_ticks])\n",
    "        ax.set_xlabel('Buffer Size (in BDP)')\n",
    "        ax.set_ylabel(metric)\n",
    "        \n",
    "        # Group data by 'cca' column\n",
    "        grouped_data = aqm_group.groupby('cca')\n",
    "        \n",
    "        # Iterate through each CCA combination\n",
    "        for i, (cca, group) in enumerate(grouped_data):\n",
    "            # Group data by 'buffer_factor' and calculate the mean for each group\n",
    "            mean_data = group.groupby('buffer_factor')[metric].mean()\n",
    "            \n",
    "            # Plot the data for this CCA combination with marker\n",
    "            ax.plot(mean_data.index, mean_data.values, marker=markers[i % len(markers)], label=f'CCA {cca}')\n",
    "        \n",
    "        # Set Y limits for each metric\n",
    "        if metric == 'jfi':\n",
    "            ax.set_ylim(0, 1)\n",
    "        elif metric == 'loss_percentage':\n",
    "            ax.set_ylim(0, 25)\n",
    "        elif metric == 'utilization':\n",
    "            ax.set_ylim(90, 102)\n",
    "        elif metric == 'buffer_occupancy':\n",
    "            ax.set_ylim(0, 100)\n",
    "    \n",
    "        ax.grid(True)\n",
    "\n",
    "# Create a single legend for all subplots on the right side\n",
    "axes[0].legend(bbox_to_anchor=(1.1, 1), loc='upper left')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plots to PDF\n",
    "plt.savefig('experiment_results_9seconds.pdf', format='pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4605917b-496e-45cb-86d3-353e4720cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def cap_utilization(df, column='utilization', cap_value=100):\n",
    "    df.loc[df[column] > cap_value, column] = cap_value\n",
    "    return df\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14,          # General font size\n",
    "    'axes.titlesize': 16,     # Font size of the axes titles\n",
    "    'axes.labelsize': 14,     # Font size of the x and y labels\n",
    "    'xtick.labelsize': 12,    # Font size of the x tick labels\n",
    "    'ytick.labelsize': 12,    # Font size of the y tick labels\n",
    "    'legend.fontsize': 12,    # Font size of the legend\n",
    "    'figure.titlesize': 18    # Font size of the figure title\n",
    "})\n",
    "\n",
    "\n",
    "# Read the CSV files into DataFrames\n",
    "data_9sec = pd.read_csv('9seconds_all.csv')\n",
    "data_5min = pd.read_csv('5_min_original_exps.csv')\n",
    "\n",
    "# Cap utilization values at 100\n",
    "data_9sec = cap_utilization(data_9sec)\n",
    "data_5min = cap_utilization(data_5min)\n",
    "\n",
    "# Optionally, save the modified DataFrames back to the CSV files\n",
    "data_9sec.to_csv('9seconds_all_modified.csv', index=False)\n",
    "data_5min.to_csv('5_min_original_exps_modified.csv', index=False)\n",
    "\n",
    "# Read the CSV files into DataFrames\n",
    "#data_9sec = pd.read_csv('9seconds_all.csv')\n",
    "#data_5min = pd.read_csv('5_min_original_exps.csv')\n",
    "\n",
    "# Define the metrics you want to plot\n",
    "metrics = ['jfi', 'loss_percentage', 'utilization', 'buffer_occupancy']\n",
    "metric_ylabels = ['Jain Fairness', 'Loss [%]', 'Utilization [%]', 'Buffer Occupancy [%]']\n",
    "#metric_titles = ['JFI', 'Loss (%)', 'Utilization (%)', 'Buffer Occupancy (%)']\n",
    "\n",
    "# Define color and marker mappings\n",
    "label_to_color_map = {\n",
    "    'bbr-bbr': (0.36, 0.54, 0.66),\n",
    "    'bbr-reno': (0.74, 0.2, 0.64),\n",
    "    'bbr-cubic': (0.44, 0.16, 0.39),\n",
    "    'bbr2-bbr2': (0.89, 0.61, 0.06),\n",
    "    'bbr2-reno': (0.52, 0.39, 0.44),\n",
    "    'bbr2-cubic': (0.56, 0.74, 0.86),\n",
    "    'bbr-bbr2': (0.91, 0.17, 0.31),\n",
    "}\n",
    "\n",
    "label_to_marker_map = {\n",
    "    'bbr-bbr': 'D',\n",
    "    'bbr-reno': 'P',\n",
    "    'bbr-cubic': 'X',\n",
    "    'bbr2-bbr2': 'h',\n",
    "    'bbr-bbr2': 'd',\n",
    "    'bbr2-reno': 'o',\n",
    "    'bbr2-cubic': 's',\n",
    "}\n",
    "\n",
    "# Create subplots with 2 columns to align the same metrics from both datasets side by side\n",
    "num_metrics = len(metrics)\n",
    "num_rows = num_metrics\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=2, figsize=(12, 4 * num_rows))\n",
    "\n",
    "x_ticks = [1, 2, 3, 4, 5, 6, 7, 8, 16, 32, 64]\n",
    "\n",
    "# Function to plot data for a given ax, dataset, metric, title, and ylabel\n",
    "def plot_data(ax, data, metric, title, ylabel=None):\n",
    "    ax.set_title(title)\n",
    "    ax.set_xscale('log', base=2)\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticklabels([str(x) for x in x_ticks])\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel)\n",
    "    \n",
    "    # Group data by 'cca' column\n",
    "    grouped_data = data.groupby('cca')\n",
    "    \n",
    "    # Legend handlers\n",
    "    legend_handles = []\n",
    "    \n",
    "    # Iterate through each CCA combination\n",
    "    for cca, group in grouped_data:\n",
    "        # Group data by 'buffer_factor' and calculate the mean and std deviation for each group\n",
    "        stats = group.groupby('buffer_factor')[metric].agg(['mean', 'std'])\n",
    "        color = label_to_color_map.get(cca, 'gray')  # Default to gray if not found\n",
    "        marker = label_to_marker_map.get(cca, 'o')   # Default to 'o' if not found\n",
    "        \n",
    "        # Plot the data for this CCA combination with error bars and lines\n",
    "        line, caplines, barlinecols = ax.errorbar(stats.index, stats['mean'], yerr=stats['std'], fmt=marker, linestyle='-', color=color, capsize=5, label=f'CCA {cca}', markerfacecolor='none')\n",
    "\n",
    "        # Create a line object for legend without error bar\n",
    "        legend_line = plt.Line2D([0], [0], color=color, marker=marker, linestyle='-', label=f'CCA {cca}', markerfacecolor='none')\n",
    "        legend_handles.append(legend_line)\n",
    "    \n",
    "    # Set Y limits for each metric\n",
    "    if metric == 'jfi':\n",
    "        ax.set_ylim(0, 1)\n",
    "    elif metric == 'loss_percentage':\n",
    "        ax.set_ylim(0, 30)\n",
    "    elif metric == 'utilization':\n",
    "        ax.set_ylim(90, 102)\n",
    "    elif metric == 'buffer_occupancy':\n",
    "        ax.set_ylim(0, 100)\n",
    "\n",
    "    ax.grid(True)\n",
    "    return legend_handles\n",
    "\n",
    "# Iterate through each metric\n",
    "for idx, metric in enumerate(metrics):\n",
    "    # Plot for 9-second data\n",
    "    ax_9sec = axes[idx, 0]  # Select the subplot for 9-second data\n",
    "    legend_handles_9sec = plot_data(ax_9sec, data_9sec, metric, f\"9 Seconds Experiment\", ylabel=metric_ylabels[idx])\n",
    "\n",
    "    # Plot for 5-minute data\n",
    "    ax_5min = axes[idx, 1]  # Select the subplot for 5-minute data\n",
    "    legend_handles_5min = plot_data(ax_5min, data_5min, metric, f\"5 Minutes Experiment\")\n",
    "\n",
    "    # Add legend to the rightmost subplot in each row\n",
    "    ax_5min.legend(handles=legend_handles_5min, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    # Set xlabel for the bottom row only\n",
    "    if idx == num_metrics - 1:\n",
    "        ax_9sec.set_xlabel('Buffer Size (in BDP)')\n",
    "        ax_5min.set_xlabel('Buffer Size (in BDP)')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plots to PDF\n",
    "plt.savefig('2022_experiment_results_9_seconds_5_min.pdf', format='pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339aca82-9dc9-451c-8328-4f2269f4d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Load JSON data\n",
    "with open('2024-05-10--15-11-12-all.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Extract relevant data and flatten it\n",
    "records = []\n",
    "for entry in data:\n",
    "    bdp = math.ceil(100*1e6 / (1500 * 8 * 1000)*10)\n",
    "    cc_list = entry['cc_combination']\n",
    "    if \"CUBIC\" in cc_list and \"RENO\" in cc_list:\n",
    "        continue\n",
    "    \n",
    "    if len(cc_list) == 1:\n",
    "        cc_combination = f\"{cc_list[0].lower()}-{cc_list[0].lower()}\"\n",
    "    else:\n",
    "        cc_combination = '-'.join(sorted(cc_list)).lower()\n",
    "    record = {\n",
    "        'cca':  cc_combination,\n",
    "        'buffer_factor': entry['switch_buffer'],\n",
    "        'buffer_occupancy': (entry['avg_queue']/int(entry['switch_buffer']*bdp))*100,\n",
    "        'jfi': entry['jain_fairness_index'],\n",
    "        'loss_percentage': entry['loss']*100,\n",
    "        'utilization': entry['utilization']*100\n",
    "    }\n",
    "    records.append(record)\n",
    "\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('model_validation_data.csv', index=False)\n",
    "\n",
    "print(\"JSON data successfully converted to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52958340-0fdc-48a6-a7c3-6cb6e8a16452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def cap_utilization(df, column='utilization', cap_value=100):\n",
    "    df.loc[df[column] > cap_value, column] = cap_value\n",
    "    return df\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 16,          # General font size\n",
    "    'axes.titlesize': 18,     # Font size of the axes titles\n",
    "    'axes.labelsize': 16,     # Font size of the x and y labels\n",
    "    'xtick.labelsize': 14,    # Font size of the x tick labels\n",
    "    'ytick.labelsize': 14,    # Font size of the y tick labels\n",
    "    'legend.fontsize': 14,    # Font size of the legend\n",
    "    'figure.titlesize': 20    # Font size of the figure title\n",
    "})\n",
    "\n",
    "# Read the CSV files into DataFrames\n",
    "data_bbr3 = pd.read_csv('combined_bbrv3.csv')\n",
    "data_5min = pd.read_csv('5_min_original_exps.csv')\n",
    "data_model = pd.read_csv('model_validation_data.csv')\n",
    "\n",
    "# Cap utilization values at 100\n",
    "data_bbr3 = cap_utilization(data_bbr3)\n",
    "data_5min = cap_utilization(data_5min)\n",
    "data_model = cap_utilization(data_model)\n",
    "\n",
    "# Optionally, save the modified DataFrames back to the CSV files\n",
    "data_5min.to_csv('5_min_original_exps_modified.csv', index=False)\n",
    "\n",
    "# Define the metrics you want to plot\n",
    "metrics = ['jfi', 'loss_percentage', 'utilization', 'buffer_occupancy']\n",
    "metric_ylabels = ['Jain Fairness', 'Loss [%]', 'Utilization [%]', 'Buffer Occupancy [%]']\n",
    "\n",
    "# Define color and marker mappings\n",
    "label_to_color_map = {\n",
    "    'bbr-bbr': (0.36, 0.54, 0.66),\n",
    "    'bbr-reno': (0.74, 0.2, 0.64),\n",
    "    'bbr-cubic': (0.44, 0.16, 0.39),\n",
    "    'bbr2-bbr2': (0.89, 0.61, 0.06),\n",
    "    'bbr2-reno': (0.52, 0.39, 0.44),\n",
    "    'bbr2-cubic': (0.56, 0.74, 0.86),\n",
    "    'bbr-bbr2': (0.91, 0.17, 0.31),\n",
    "    'bbr3-bbr3': (0.68, 0.85, 0.9),\n",
    "    'bbr3-bbr2': (0.89, 0.47, 0.76),\n",
    "    'bbr3-bbr': (0.45, 0.75, 0.45),\n",
    "    'bbr3-cubic': (0.91, 0.64, 0.42),\n",
    "    'bbr3-reno': (0.82, 0.33, 0.32),\n",
    "}\n",
    "\n",
    "label_to_marker_map = {\n",
    "    'bbr-bbr': 'D',\n",
    "    'bbr-reno': 'P',\n",
    "    'bbr-cubic': 'X',\n",
    "    'bbr2-bbr2': 'h',\n",
    "    'bbr-bbr2': 'd',\n",
    "    'bbr2-reno': 'o',\n",
    "    'bbr2-cubic': 's',\n",
    "    'bbr3-bbr3': '^',\n",
    "    'bbr3-bbr2': 'v',\n",
    "    'bbr3-bbr': '>',\n",
    "    'bbr3-cubic': '<',\n",
    "    'bbr3-reno': 'p',\n",
    "}\n",
    "\n",
    "# Create subplots with 3 columns to align the same metrics from both datasets side by side and add the model data\n",
    "num_metrics = len(metrics)\n",
    "num_rows = num_metrics\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=3, figsize=(15, 3 * num_rows))\n",
    "\n",
    "x_ticks = [1, 2, 3, 4, 5, 6, 7, 8, 16, 32, 64]\n",
    "\n",
    "# Function to plot data for a given ax, dataset, metric, x_param, y_param, group_param, ylabel, title, show_xlabel, show_title\n",
    "def plot_data(ax, data, metric, x_param, y_param, group_param, ylabel=None, title=None, show_xlabel=False, show_title=False):\n",
    "    if show_title:\n",
    "        ax.set_title(title)\n",
    "    ax.set_xscale('log', base=2)\n",
    "    if show_xlabel:\n",
    "        ax.set_xticks(x_ticks)\n",
    "        ax.set_xticklabels([str(x) for x in x_ticks])\n",
    "    else:\n",
    "        ax.set_xticks(x_ticks)\n",
    "        ax.set_xticklabels([])\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel)\n",
    "    else:\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "    # Group data by 'group_param' column\n",
    "    grouped_data = data.groupby(group_param)\n",
    "\n",
    "    # Legend handlers\n",
    "    legend_handles = []\n",
    "\n",
    "    # Iterate through each group combination\n",
    "    for group_name, group in grouped_data:\n",
    "        # Group data by 'x_param' and calculate the mean and std deviation for each group\n",
    "        stats = group.groupby(x_param)[y_param].agg(['mean', 'std', 'sem'])\n",
    "        color = label_to_color_map.get(group_name, 'gray')  # Default to gray if not found\n",
    "        marker = label_to_marker_map.get(group_name, 'o')   # Default to 'o' if not found\n",
    "\n",
    "        # Plot the data for this group combination with error bars and lines\n",
    "        line, caplines, barlinecols = ax.errorbar(stats.index, stats['mean'], yerr=stats['sem'], fmt=marker, linestyle='-', color=color, capsize=5, label=f'CCA {group_name}', markerfacecolor='none')\n",
    "        # Create a line object for legend without error bar\n",
    "        legend_line = plt.Line2D([0], [0], color=color, marker=marker, linestyle='-', label=f'{group_name}', markerfacecolor='none')\n",
    "        legend_handles.append(legend_line)\n",
    "\n",
    "    # Set Y limits for each metric\n",
    "    if y_param == 'jfi':\n",
    "        ax.set_ylim(0, 1.1)\n",
    "        ax.set_yticks(np.arange(0, 1.1, 0.2))\n",
    "    elif y_param == 'loss_percentage':\n",
    "        ax.set_ylim(-1, 30)\n",
    "        ax.set_yticks(np.arange(0, 31, 5))\n",
    "    elif y_param == 'utilization':\n",
    "        ax.set_ylim(90, 101)\n",
    "        ax.set_yticks(np.arange(90, 101, 2))\n",
    "    elif y_param == 'buffer_occupancy':\n",
    "        ax.set_ylim(0, 101)\n",
    "        ax.set_yticks(np.arange(0, 101, 20))\n",
    "\n",
    "    return legend_handles\n",
    "\n",
    "# Collect all unique legend handles\n",
    "unique_labels = set()\n",
    "all_legend_handles = []\n",
    "\n",
    "# Iterate through each metric\n",
    "for idx, metric in enumerate(metrics):\n",
    "    show_xlabel = (idx == num_metrics - 1)\n",
    "    show_title = True  # Titles are on the first row only\n",
    "    # Plot for model data\n",
    "    ax_model = axes[idx, 0]  # Select the subplot for model data\n",
    "    legend_handles_model = plot_data(ax_model, data_model, metric, 'buffer_factor', metric, 'cca', ylabel=metric_ylabels[idx], title=\"Model\" if idx == 0 else None, show_xlabel=show_xlabel, show_title=idx == 0)\n",
    "    for handle in legend_handles_model:\n",
    "        if handle.get_label() not in unique_labels:\n",
    "            unique_labels.add(handle.get_label())\n",
    "            all_legend_handles.append(handle)\n",
    "\n",
    "    # Plot for 5-minute data\n",
    "    ax_5min = axes[idx, 1]  # Select the subplot for 5-minute data\n",
    "    legend_handles_5min = plot_data(ax_5min, data_5min, metric, 'buffer_factor', metric, 'cca', ylabel=None, title=\"Experiment\" if idx == 0 else None, show_xlabel=show_xlabel, show_title=idx == 0)\n",
    "    for handle in legend_handles_5min:\n",
    "        if handle.get_label() not in unique_labels:\n",
    "            unique_labels.add(handle.get_label())\n",
    "            all_legend_handles.append(handle)\n",
    "\n",
    "    # Plot for BBR3 data\n",
    "    ax_bbr3 = axes[idx, 2]  # Select the subplot for BBR3 data\n",
    "    legend_handles_bbr3 = plot_data(ax_bbr3, data_bbr3, metric, 'buffer_factor', metric, 'cca', ylabel=None, title=\"BBRv3 Experiment\" if idx == 0 else None, show_xlabel=show_xlabel, show_title=idx == 0)\n",
    "    for handle in legend_handles_bbr3:\n",
    "        if handle.get_label() not in unique_labels:\n",
    "            unique_labels.add(handle.get_label())\n",
    "            all_legend_handles.append(handle)\n",
    "\n",
    "    # Add x-axis label for the bottom row\n",
    "    if show_xlabel:\n",
    "        ax_model.set_xlabel('Buffer Size (in BDP)')\n",
    "        ax_5min.set_xlabel('Buffer Size (in BDP)')\n",
    "        ax_bbr3.set_xlabel('Buffer Size (in BDP)')\n",
    "\n",
    "# Add a single horizontal legend to the top of the figure\n",
    "fig.legend(handles=all_legend_handles, loc='upper center', bbox_to_anchor=(0.5, 1), ncol=len(all_legend_handles)//2)\n",
    "\n",
    "# Adjust layout to make room for the legend\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# Save plots to PDF with tight bounding box\n",
    "plt.savefig('2022_experiment_results_9_seconds_5_min_model_final.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
